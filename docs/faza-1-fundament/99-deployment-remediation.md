# Faza 1 / Zadanie 99: Wdro≈ºenie serwis√≥w aplikacyjnych na serwerze Nebula

<!--
LLM CONTEXT PROMPT:
To zadanie naprawcze ma na celu wdro≈ºenie WSZYSTKICH brakujƒÖcych serwis√≥w aplikacyjnych z Fazy 1 na serwerze Nebula.
Obecnie tylko infrastruktura observability dzia≈Ça - brak jakichkolwiek dzia≈ÇajƒÖcych aplikacji Detektor.

STRATEGIA CI/CD:
- Obrazy Docker sƒÖ budowane w GitHub Actions przy ka≈ºdym push na main
- Obrazy publikowane do GitHub Container Registry (ghcr.io)
- Serwer Nebula TYLKO pobiera gotowe obrazy - NIGDY nie buduje lokalnie
- Deploy odbywa siƒô przez ./scripts/deploy-to-nebula.sh lub automatycznie z GitHub Actions
-->

## Cel zadania

Wdro≈ºyƒá wszystkie brakujƒÖce serwisy aplikacyjne z Fazy 1 na serwerze Nebula, zapewniajƒÖc dzia≈ÇajƒÖce przyk≈Çady wykorzystania infrastruktury observability, GPU oraz frame tracking, tworzƒÖc solidny fundament dla Fazy 2.

## üöÄ Strategia CI/CD - ObowiƒÖzujƒÖcy Standard

<!--
LLM CONTEXT PROMPT:
TEN SECTION DEFINIUJE OBOWIƒÑZUJƒÑCY STANDARD dla WSZYSTKICH zada≈Ñ w CA≈ÅYM PROJEKCIE.
Ka≈ºdy future task musi u≈ºywaƒá tej strategii CI/CD.
-->

### Workflow Deployment

1. **Build w GitHub Actions** (automatyczny):
   - Trigger: push na branch `main`
   - Buduje wszystkie obrazy Docker dla serwis√≥w
   - Publikuje do `ghcr.io/hretheum/bezrobocie-detektor/[service]:latest`
   - Uruchamia siƒô w `.github/workflows/deploy.yml`

2. **Deploy na Nebula** (automatyczny lub rƒôczny):
   - **Automatyczny**: GitHub Actions deployuje po udanym build
   - **Rƒôczny**: `./scripts/deploy-to-nebula.sh`
   - Pobiera obrazy z registry (NIGDY nie buduje lokalnie)
   - Aktualizuje docker-compose na serwerze
   - Restartuje serwisy

3. **Walidacja** (automatyczna):
   - Health checks wszystkich serwis√≥w
   - Verification connectivity z observability stack
   - GPU tests (je≈õli applicable)

### üîß Komendy dla LLM

```bash
# Build i deploy (pe≈Çny flow):
git add . && git commit -m "feat: deploy new service" && git push origin main

# Deploy z istniejƒÖcych obraz√≥w:
./scripts/deploy-to-nebula.sh

# Health check stack:
ssh nebula "/opt/detektor/scripts/health-check-all.sh"

# Logs:
ssh nebula "cd /opt/detektor && docker-compose logs [service-name]"
```

### ‚ö†Ô∏è WA≈ªNE: Co NIGDY nie robiƒá

- ‚ùå `docker build` na serwerze produkcyjnym
- ‚ùå Kopiowanie kodu ≈∫r√≥d≈Çowego na serwer
- ‚ùå Manual management docker-compose na serwerze
- ‚ùå Hardkodowanie image tags w compose files

### ‚úÖ Co robiƒá

- ‚úÖ Commit kod ‚Üí GitHub Actions buduje ‚Üí deploy z registry
- ‚úÖ U≈ºywaj `./scripts/deploy-to-nebula.sh` do deployment
- ‚úÖ Pull images z `ghcr.io/hretheum/bezrobocie-detektor/`
- ‚úÖ Wszystkie deployment commands przez automation

## Blok 0: Prerequisites check - KRYTYCZNE NA SERWERZE ‚ö†Ô∏è

<!--
LLM PROMPT: Ten blok jest ABSOLUTNIE KRYTYCZNY.
Ka≈ºda komenda MUSI byƒá poprzedzona "ssh nebula".
Je≈õli cokolwiek nie przejdzie, ZATRZYMAJ wykonanie i napraw problem.
-->

#### Zadania atomowe

1. **[x] Weryfikacja dostƒôpu SSH i uprawnie≈Ñ**
   - **Metryka**: SSH dzia≈Ça, sudo access, git configured
   - **Walidacja NA SERWERZE**:
     ```bash
     ssh nebula "whoami && sudo -n true && echo 'SSH + sudo OK' || echo 'FAIL'"
     ssh nebula "cd /opt/detektor && git remote -v | grep origin"
     ssh nebula "docker ps > /dev/null && echo 'Docker access OK' || echo 'FAIL'"
     ```
   - **Quality Gate**: All checks return OK
   - **Guardrails**: Abort if any check fails
   - **Czas**: 0.5h

2. **[x] Weryfikacja infrastruktury observability**
   - **Metryka**: Prometheus, Grafana, Jaeger healthy
   - **Walidacja NA SERWERZE**:
     ```bash
     ssh nebula "curl -s http://localhost:9090/-/healthy | grep 'Prometheus is Healthy'"
     ssh nebula "curl -s http://localhost:3000/api/health | jq '.database'"
     ssh nebula "curl -s http://localhost:16686/ | grep -q 'Jaeger UI' && echo 'Jaeger OK'"
     ```
   - **Quality Gate**: All services responding
   - **Guardrails**: Fix unhealthy services first
   - **Czas**: 0.5h

3. **[x] Weryfikacja GPU i przestrzeni dyskowej**
   - **Metryka**: GPU accessible, >20GB free space
   - **Walidacja NA SERWERZE**:
     ```bash
     ssh nebula "nvidia-smi --query-gpu=name,memory.free --format=csv"
     ssh nebula "df -h / | tail -1 | awk '{print \$4}' | grep -E '^[2-9][0-9]G|^[1-9][0-9]{2}G'"
     ssh nebula "docker system df"
     ```
   - **Quality Gate**: GPU detected, sufficient space
   - **Guardrails**: Clean up if <20GB free
   - **Czas**: 0.5h

## Dekompozycja na bloki zada≈Ñ

### Blok 1: Fix telemetry service i deploy example OTEL service

<!--
LLM PROMPT: Najpierw napraw restartujƒÖcy siƒô kontener, potem deploy przyk≈Çadu.
PAMIƒòTAJ: ssh nebula przed ka≈ºdƒÖ komendƒÖ!
-->

#### Zadania atomowe

1. **[ ] Debug i naprawa telemetry_service-jaeger-1**
   - **Metryka**: Container running stable, no restarts
   - **Walidacja NA SERWERZE**:
     ```bash
     ssh nebula "docker logs telemetry_service-jaeger-1 --tail 100 | grep -i error"
     ssh nebula "docker compose -f docker-compose.observability.yml ps telemetry_service-jaeger-1"
     # Po naprawie:
     ssh nebula "docker ps | grep telemetry_service-jaeger-1 | grep -v Restarting"
     ```
   - **Quality Gate**: Zero restarts in 5 minutes
   - **Guardrails**: Remove if unfixable
   - **Czas**: 1h

2. **[ ] Deploy OpenTelemetry example service z registry**
   - **Metryka**: Example service running, exporting traces
   - **Prerequisites**: Obrazy muszƒÖ byƒá zbudowane w GitHub Actions i dostƒôpne w ghcr.io
   - **Walidacja NA SERWERZE**:
     ```bash
     # Pull latest image from registry
     ssh nebula "docker pull ghcr.io/hretheum/bezrobocie-detektor/example-otel:latest"
     # Deploy using deployment script
     ./scripts/deploy-to-nebula.sh
     # OR manual deploy:
     ssh nebula "cd /opt/detektor && docker-compose up -d example-otel"
     # Verify
     ssh nebula "curl -s http://localhost:8005/health | jq '.status'"
     ssh nebula "curl -s http://localhost:16686/api/services | jq '.data[]' | grep -q 'example-otel'"
     ```
   - **Quality Gate**: Health check passing, traces visible
   - **Guardrails**: CPU usage <50%
   - **Czas**: 2h

3. **[ ] Verify GPU access in container**
   - **Metryka**: Container can access GPU
   - **Walidacja NA SERWERZE**:
     ```bash
     ssh nebula "docker run --rm --gpus all nvidia/cuda:12.0-base nvidia-smi"
     ssh nebula "docker exec example-otel python -c 'import torch; print(f\"GPU available: {torch.cuda.is_available()}\")"
     ```
   - **Quality Gate**: GPU detected in container
   - **Guardrails**: Memory allocation works
   - **Czas**: 0.5h

#### Metryki sukcesu bloku

- No containers in restart loop
- Example service exporting traces to Jaeger
- GPU accessible from containers
- Metrics visible in Prometheus

### Blok 2: Deploy Frame Tracking Service z PostgreSQL

<!--
LLM PROMPT: Frame tracking to CORE functionality.
Deploy z TimescaleDB dla time-series data.
-->

#### Zadania atomowe

1. **[ ] Deploy PostgreSQL z TimescaleDB**
   - **Metryka**: PostgreSQL running with TimescaleDB extension
   - **Walidacja NA SERWERZE**:
     ```bash
     # Deploy
     ssh nebula "cd /opt/detektor && docker compose -f docker-compose.storage.yml up -d postgres"
     # Verify TimescaleDB
     ssh nebula "docker exec postgres psql -U detektor -c 'CREATE EXTENSION IF NOT EXISTS timescaledb;'"
     ssh nebula "docker exec postgres psql -U detektor -c '\\dx' | grep timescaledb"
     ```
   - **Quality Gate**: Extension loaded, port 5432 accessible
   - **Guardrails**: Data persistence configured
   - **Czas**: 1.5h

2. **[ ] Deploy Frame Tracking Service z registry**
   - **Metryka**: Frame tracking API running with event sourcing
   - **Prerequisites**:
     - PostgreSQL z TimescaleDB running (poprzednie zadanie)
     - Image zbudowany w GitHub Actions: ghcr.io/hretheum/bezrobocie-detektor/frame-tracking:latest
   - **Walidacja NA SERWERZE**:
     ```bash
     # Pull latest image from registry
     ssh nebula "docker pull ghcr.io/hretheum/bezrobocie-detektor/frame-tracking:latest"
     # Deploy using deployment script
     ./scripts/deploy-to-nebula.sh
     # OR manual deploy:
     ssh nebula "cd /opt/detektor && docker-compose up -d frame-tracking"
     # Verify API
     ssh nebula "curl -s http://localhost:8006/health | jq '.database'"
     ssh nebula "curl -s http://localhost:8006/api/v1/frames -X POST -H 'Content-Type: application/json' -d '{\"frame_id\":\"test-001\",\"timestamp\":\"2025-01-19T12:00:00Z\",\"camera_id\":\"cam-01\"}'"
     ```

   - **Quality Gate**: API responding, data persisted

   - **Guardrails**: Response time <100ms

   - **Czas**: 2h

3. **[ ] Integration test z observability**
   - **Metryka**: Traces, metrics, logs flowing correctly
   - **Walidacja NA SERWERZE**:
     ```bash
     # Generate test traffic
     ssh nebula "for i in {1..100}; do curl -s http://localhost:8006/api/v1/frames/test-\$i > /dev/null; done"
     # Check traces
     ssh nebula "curl -s 'http://localhost:16686/api/traces?service=frame-tracking&limit=10' | jq '.data | length'"
     # Check metrics
     ssh nebula "curl -s http://localhost:9090/api/v1/query?query=frame_tracking_requests_total | jq '.data.result | length'"
     ```
   - **Quality Gate**: >90% requests traced
   - **Guardrails**: No errors in logs
   - **Czas**: 1h

#### Metryki sukcesu bloku

- PostgreSQL z TimescaleDB operational
- Frame tracking API <100ms response time
- Event sourcing dla pe≈Çnej historii klatek
- Full observability integration

### Blok 3: Deploy Base Service Template jako dzia≈ÇajƒÖcy przyk≈Çad

<!--
LLM PROMPT: Template musi byƒá DZIA≈ÅAJƒÑCYM serwisem, nie tylko kodem.
To bƒôdzie wzorzec dla wszystkich przysz≈Çych serwis√≥w.
-->

#### Zadania atomowe

1. **[ ] Przygotowanie service template z wszystkimi best practices**
   - **Metryka**: Template service implementing all patterns
   - **Walidacja NA SERWERZE**:
     ```bash
     ssh nebula "cd /opt/detektor && ls -la services/base-template/"
     ssh nebula "cd /opt/detektor && grep -r '@traced' services/base-template/ | wc -l"
     ssh nebula "cd /opt/detektor && grep -r 'prometheus_client' services/base-template/ | wc -l"
     ```
   - **Quality Gate**: All patterns present
   - **Guardrails**: 100% test coverage
   - **Czas**: 2h

2. **[ ] Deploy echo-service z registry**
   - **Metryka**: Working service demonstrating all features
   - **Prerequisites**: Echo service zbudowany z base-template w GitHub Actions
   - **Walidacja NA SERWERZE**:
     ```bash
     # Pull latest image from registry
     ssh nebula "docker pull ghcr.io/hretheum/bezrobocie-detektor/echo-service:latest"
     # Deploy using deployment script
     ./scripts/deploy-to-nebula.sh
     # OR manual deploy:
     ssh nebula "cd /opt/detektor && docker-compose up -d echo-service"
     # Test features
     ssh nebula "curl -s http://localhost:8007/health | jq '.features'"
     ssh nebula "curl -s http://localhost:8007/echo -X POST -d '{\"message\":\"test\"}' | jq '.correlation_id'"
     ```
   - **Quality Gate**: All endpoints working
   - **Guardrails**: Memory <500MB
   - **Czas**: 1.5h

3. **[ ] Create Grafana dashboard dla template**
   - **Metryka**: Dashboard showing all key metrics
   - **Walidacja NA SERWERZE**:
     ```bash
     # Import dashboard
     ssh nebula "curl -s -X POST http://admin:admin@localhost:3000/api/dashboards/db \
       -H 'Content-Type: application/json' \
       -d @/opt/detektor/dashboards/service-template.json"
     # Verify panels
     ssh nebula "curl -s http://localhost:3000/api/dashboards/uid/service-template | jq '.dashboard.panels | length'"
     ```
   - **Quality Gate**: Dashboard has >10 panels
   - **Guardrails**: All queries return data
   - **Czas**: 1h

#### Metryki sukcesu bloku

- Template service running with all features
- Developers can copy and modify for new services
- Full observability from day 1
- Documentation in code

### Blok 4: GPU utilization demo service

<!--
LLM PROMPT: Musimy pokazaƒá ≈ºe GPU faktycznie dzia≈Ça.
Simple ML inference service jako dow√≥d koncepcji.
-->

#### Zadania atomowe

1. **[ ] Deploy GPU demo service z registry**
   - **Metryka**: Service using GPU for inference
   - **Prerequisites**: GPU-enabled image zbudowany w GitHub Actions
   - **Walidacja NA SERWERZE**:
     ```bash
     # Pull latest GPU image from registry
     ssh nebula "docker pull ghcr.io/hretheum/bezrobocie-detektor/gpu-demo:latest"
     # Deploy using deployment script (with GPU support)
     ./scripts/deploy-to-nebula.sh
     # OR manual deploy:
     ssh nebula "cd /opt/detektor && docker-compose up -d gpu-demo"
     # Test GPU usage
     ssh nebula "nvidia-smi | grep gpu-demo"
     ssh nebula "curl -s http://localhost:8008/inference -X POST -F 'image=@test-image.jpg' | jq '.gpu_used'"
     ```
   - **Quality Gate**: GPU memory allocated
   - **Guardrails**: GPU temp <80¬∞C
   - **Czas**: 2h

2. **[ ] GPU metrics integration**
   - **Metryka**: GPU metrics in Prometheus/Grafana
   - **Walidacja NA SERWERZE**:
     ```bash
     ssh nebula "curl -s http://localhost:9400/metrics | grep -E 'nvidia_gpu_temperature|nvidia_gpu_memory_used'"
     ssh nebula "curl -s http://localhost:9090/api/v1/query?query=nvidia_gpu_memory_used_bytes | jq '.data.result | length'"
     ```
   - **Quality Gate**: GPU metrics collected
   - **Guardrails**: Alerts for high temp
   - **Czas**: 1h

#### Metryki sukcesu bloku

- At least one service actively using GPU
- GPU metrics visible in monitoring
- Inference working correctly

### Blok 5: Final integration test i dokumentacja

<!--
LLM PROMPT: Weryfikacja ≈ºe WSZYSTKO dzia≈Ça razem.
To jest final checkpoint przed FazƒÖ 2.
-->

#### Zadania atomowe

1. **[ ] End-to-end integration test wszystkich serwis√≥w**
   - **Metryka**: All services communicating correctly
   - **Walidacja NA SERWERZE**:
     ```bash
     # Full stack health check
     ssh nebula "cd /opt/detektor && ./scripts/health-check-all.sh"
     # E2E test flow
     ssh nebula "cd /opt/detektor && python tests/e2e/test_full_pipeline.py"
     # Verify no errors
     ssh nebula "docker compose logs --since 10m | grep -i error | wc -l"
     # Should be 0
     ```
   - **Quality Gate**: All tests passing
   - **Guardrails**: <5% error rate
   - **Czas**: 2h

2. **[ ] Generate deployment documentation**
   - **Metryka**: Complete deployment guide created
   - **Walidacja NA SERWERZE**:
     ```bash
     ssh nebula "cd /opt/detektor && docker compose ps --format json > docs/deployment-status.json"
     ssh nebula "cd /opt/detektor && ./scripts/generate-deployment-docs.sh"
     ssh nebula "ls -la /opt/detektor/docs/DEPLOYMENT_GUIDE_FAZA1.md"
     ```
   - **Quality Gate**: Guide covers all services
   - **Guardrails**: Includes troubleshooting
   - **Czas**: 1h

3. **[ ] 24h stability verification**
   - **Metryka**: No crashes or memory leaks in 24h
   - **Walidacja NA SERWERZE**:
     ```bash
     # Start monitoring
     ssh nebula "cd /opt/detektor && ./scripts/start-stability-test.sh"
     # After 24h check
     ssh nebula "cd /opt/detektor && ./scripts/check-stability-results.sh"
     ```
   - **Quality Gate**: Zero service restarts
   - **Guardrails**: Memory growth <10%
   - **Czas**: 24h (passive)

#### Metryki sukcesu bloku

- Full stack operational on Nebula
- Zero errors in integration tests
- Documentation complete and accurate
- System stable for 24h

## Ca≈Ço≈õciowe metryki sukcesu zadania

1. **Deployment completeness**: 100% serwis√≥w z Fazy 1 dzia≈ÇajƒÖcych na Nebuli
2. **Observability**: Ka≈ºdy serwis ma traces, metrics, logs
3. **GPU utilization**: Przynajmniej 1 serwis aktywnie u≈ºywa GPU
4. **Stability**: Zero restart√≥w w ciƒÖgu 24h
5. **Performance**: Response times <100ms dla wszystkich API
6. **Documentation**: Deployment guide umo≈ºliwia odtworzenie w <30min

## Deliverables

1. `/opt/detektor/services/example-otel/` - Working OTEL example
2. `/opt/detektor/services/frame-tracking/` - Frame tracking z event sourcing
3. `/opt/detektor/services/echo-service/` - Base template demonstration
4. `/opt/detektor/services/gpu-demo/` - GPU utilization proof
5. `/opt/detektor/docker-compose.yml` - Updated with all services
6. `/opt/detektor/docker-compose.storage.yml` - PostgreSQL/TimescaleDB
7. `/opt/detektor/docker-compose.gpu.yml` - GPU services config
8. `/opt/detektor/docs/DEPLOYMENT_GUIDE_FAZA1.md` - Complete guide
9. `/opt/detektor/scripts/health-check-all.sh` - Stack validation
10. `/opt/detektor/dashboards/*.json` - Grafana dashboards

## Narzƒôdzia

- **Docker Compose**: Orchestration wszystkich serwis√≥w
- **PostgreSQL + TimescaleDB**: Frame tracking storage
- **Python 3.11+**: Service implementation
- **NVIDIA Container Toolkit**: GPU access
- **curl/jq**: Validation and testing

## Zale≈ºno≈õci

- **Wymaga**:
  - Dzia≈ÇajƒÖca infrastruktura observability (ju≈º jest)
  - Docker z GPU support (ju≈º jest)
  - SSH access do Nebula (verified w Blok 0)
- **Blokuje**:
  - Ca≈ÇƒÖ Fazƒô 2 - bez dzia≈ÇajƒÖcych przyk≈Çad√≥w nie ma sensu i≈õƒá dalej

## Ryzyka i mitigacje

| Ryzyko | Prawdopodobie≈Ñstwo | Wp≈Çyw | Mitigacja | Early Warning |
|--------|-------------------|-------|-----------|---------------|
| Brak miejsca na dysku podczas budowania | ≈örednie | Wysoki | Docker prune przed budowaniem | df -h shows <10GB |
| Konflikty port√≥w miƒôdzy serwisami | ≈örednie | ≈öredni | Ka≈ºdy serwis ma unikalny port 800X | Bind address already in use |
| GPU nie dzia≈Ça w kontenerach | Niskie | Wysoki | Test GPU przed ka≈ºdym deploymentem | nvidia-smi fails in container |
| PostgreSQL data loss | Niskie | Wysoki | Volume mounting, regular backups | Connection refused |
| Serwisy nie komunikujƒÖ siƒô | ≈örednie | Wysoki | Wszystkie w tej samej Docker network | No traces between services |

## Rollback Plan

1. **Detekcja problemu**:
   - Services crashujƒÖ lub restartujƒÖ siƒô
   - Integration tests failing
   - GPU niedostƒôpne
   - Performance degradation >50%

2. **Kroki rollback**:
   - [ ] Stop wszystkie nowe serwisy: `ssh nebula "cd /opt/detektor && docker compose down"`
   - [ ] Zachowaj logi: `ssh nebula "cd /opt/detektor && docker compose logs > rollback-logs-$(date +%s).txt"`
   - [ ] Przywr√≥ƒá poprzedni stan: `ssh nebula "cd /opt/detektor && git checkout HEAD~1"`
   - [ ] Restart tylko core services: `ssh nebula "cd /opt/detektor && docker compose up -d prometheus grafana jaeger"`

3. **Czas rollback**: <15 minut

## Nastƒôpne kroki

Po uko≈Ñczeniu tego zadania:
1. Wszystkie serwisy Fazy 1 bƒôdƒÖ dzia≈Çaƒá na Nebuli
2. Mo≈ºemy rozpoczƒÖƒá Fazƒô 2 z solidnym fundamentem
3. Ka≈ºdy nowy serwis bƒôdzie mia≈Ç dzia≈ÇajƒÖcy przyk≈Çad do skopiowania

‚Üí Przejd≈∫ do [Faza 2 - Akwizycja danych](../../faza-2-akwizycja/README.md)

<!--
LLM FINAL REMINDER:
To zadanie jest KRYTYCZNE dla sukcesu projektu.
BEZ dzia≈ÇajƒÖcych serwis√≥w na serwerze ca≈Çy projekt to tylko "localhost development".
KA≈ªDA komenda musi byƒá wykonana przez SSH na Nebuli!
-->
