# Production environment overrides
# This file contains production-specific configuration
# Use with: docker compose -f docker/base/docker-compose.yml -f docker/environments/production/docker-compose.yml

version: "3.8"

# Global configuration for production
x-production-defaults: &production-defaults
  restart: unless-stopped
  logging:
    driver: json-file
    options:
      max-size: "10m"
      max-file: "3"
  deploy:
    resources:
      limits:
        memory: 2G
      reservations:
        memory: 512M

services:
  # Application services with production settings
  rtsp-capture:
    <<: *production-defaults
    image: ghcr.io/hretheum/detektr/rtsp-capture:${IMAGE_TAG:-latest}
    environment:
      - LOG_LEVEL=INFO
      - METRICS_ENABLED=true
      - TRACE_ENABLED=true
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: "2.0"

  frame-tracking:
    <<: *production-defaults
    image: ghcr.io/hretheum/detektr/frame-tracking:${IMAGE_TAG:-latest}
    environment:
      - LOG_LEVEL=INFO
      - METRICS_ENABLED=true
      - TRACE_ENABLED=true
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_DB=${POSTGRES_DB:-detektor}
      - POSTGRES_USER=${POSTGRES_USER:-detektor}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - DETEKTOR_DB_PASSWORD=${POSTGRES_PASSWORD}

  echo-service:
    <<: *production-defaults
    image: ghcr.io/hretheum/detektr/echo-service:${IMAGE_TAG:-latest}
    environment:
      - LOG_LEVEL=INFO
      - METRICS_ENABLED=true
    profiles:
      - demo

  example-otel:
    <<: *production-defaults
    image: ghcr.io/hretheum/detektr/example-otel:${IMAGE_TAG:-latest}
    environment:
      - LOG_LEVEL=INFO
      - OTEL_EXPORTER_OTLP_TRACES_ENDPOINT=http://jaeger:4317
      - OTEL_METRICS_EXPORTER=prometheus
    profiles:
      - demo

  base-template:
    <<: *production-defaults
    image: ghcr.io/hretheum/detektr/base-template:${IMAGE_TAG:-latest}
    ports:
      - "8000:8000"
    environment:
      - LOG_LEVEL=INFO
      - METRICS_ENABLED=true
      - OTEL_EXPORTER_OTLP_ENDPOINT=http://jaeger:4317
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_DB=${POSTGRES_DB:-detektor}
      - POSTGRES_USER=${POSTGRES_USER:-detektor}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - DETEKTOR_DB_PASSWORD=${POSTGRES_PASSWORD}

  metadata-storage:
    <<: *production-defaults
    image: ghcr.io/hretheum/detektr/metadata-storage:${IMAGE_TAG:-latest}
    environment:
      - LOG_LEVEL=INFO
      - METRICS_ENABLED=true
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_DB=${POSTGRES_DB:-detektor}
      - POSTGRES_USER=${POSTGRES_USER:-detektor}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - DETEKTOR_DB_PASSWORD=${POSTGRES_PASSWORD}

  gpu-demo:
    <<: *production-defaults
    image: ghcr.io/hretheum/detektr/gpu-demo:${IMAGE_TAG:-latest}
    environment:
      - LOG_LEVEL=INFO
      - CUDA_VISIBLE_DEVICES=0
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    profiles:
      - demo
      - gpu

  # Infrastructure services with production limits
  postgres:
    <<: *production-defaults
    image: timescale/timescaledb:latest-pg15
    environment:
      - POSTGRES_MAX_CONNECTIONS=200
      - POSTGRES_SHARED_BUFFERS=256MB
      - POSTGRES_EFFECTIVE_CACHE_SIZE=1GB
      - POSTGRES_MAINTENANCE_WORK_MEM=64MB
      - POSTGRES_CHECKPOINT_COMPLETION_TARGET=0.9
      - POSTGRES_WAL_BUFFERS=16MB
      - POSTGRES_DEFAULT_STATISTICS_TARGET=100
      - POSTGRES_RANDOM_PAGE_COST=1.1
      - POSTGRES_EFFECTIVE_IO_CONCURRENCY=200
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: "2.0"
    volumes:
      - postgres_data:/var/lib/postgresql/data

  redis:
    <<: *production-defaults
    image: redis:7-alpine
    command: >
      redis-server
      --maxmemory 1gb
      --maxmemory-policy allkeys-lru
      --save 900 1
      --save 300 10
      --save 60 10000
      --appendonly yes
      --appendfsync everysec
    deploy:
      resources:
        limits:
          memory: 1.5G
          cpus: "1.0"
    volumes:
      - redis_data:/data

  # Monitoring with retention policies
  prometheus:
    <<: *production-defaults
    image: prom/prometheus:latest
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.path=/prometheus"
      - "--storage.tsdb.retention.time=30d"
      - "--storage.tsdb.retention.size=10GB"
      - "--web.console.libraries=/usr/share/prometheus/console_libraries"
      - "--web.console.templates=/usr/share/prometheus/consoles"
      - "--web.enable-lifecycle"
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: "1.0"
    volumes:
      - prometheus_data:/prometheus

  grafana:
    <<: *production-defaults
    image: grafana/grafana:latest
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}
      - GF_INSTALL_PLUGINS=grafana-clock-panel,grafana-simple-json-datasource
      - GF_SERVER_ROOT_URL=http://nebula:3000
      - GF_ANALYTICS_REPORTING_ENABLED=false
      - GF_ANALYTICS_CHECK_FOR_UPDATES=false
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: "0.5"
    volumes:
      - grafana_data:/var/lib/grafana

  jaeger:
    <<: *production-defaults
    image: jaegertracing/all-in-one:latest
    environment:
      - SPAN_STORAGE_TYPE=memory
      - COLLECTOR_QUEUE_SIZE=10000
      - METRICS_STORAGE_TYPE=prometheus
      - MEMORY_MAX_TRACES=100000
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: "1.0"

# Production volumes
volumes:
  postgres_data:
  redis_data:
  prometheus_data:
  grafana_data:

# Production network configuration
networks:
  default:
    name: detektor-network
    external: true
