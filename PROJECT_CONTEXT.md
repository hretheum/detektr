# Kontekst Projektu Detektor - dla LLM

<!--
META LLM PROMPT:
Ten plik s≈Çu≈ºy do szybkiego wprowadzenia LLM w kontekst projektu.
Wczytaj go na poczƒÖtku ka≈ºdej nowej sesji/konwersacji.
-->

## O projekcie

**Nazwa**: System Detekcji i Automatyzacji Wizyjnej (Detektor)
**Repo**: github.com/hretheum/detektr
**Registry**: ghcr.io/hretheum/detektr/
**Typ**: Projekt hobbystyczny
**Cel**: Przechwytywanie obrazu z kamery IP + AI rozpoznawanie + automatyzacja Home Assistant

## Stack technologiczny

- **Serwer**: Ubuntu z GTX 4070 Super (16GB VRAM), i7, 64GB RAM (hostname: nebula)
- **Infrastruktura**: Docker, Docker Compose, container-first
- **CI/CD**: GitHub Actions + GitHub Container Registry (ghcr.io)
- **Jƒôzyki**: Python 3.11+, FastAPI
- **AI/ML**: YOLO, MediaPipe, Whisper, OpenAI/Anthropic API
- **Observability**: Jaeger, Prometheus, Grafana (od poczƒÖtku!)
- **Architektura**: Clean Architecture, DDD, Event Sourcing, TDD
- **Message Bus**: Redis Streams (adoptowane z eofek/detektor)
- **Secrets**: SOPS z age encryption

## Influences - eofek/detektor Analysis

**Reference**: `docs/analysis/eofek-detektor-analysis.md`
**Source Repository**: <https://github.com/eofek/detektor> (w≈Çasno≈õƒá autora - kod dostƒôpny do wykorzystania)

**ADOPTUJEMY**:

- Metrics abstraction layer pattern
- Redis Streams event-driven architecture
- GPU monitoring patterns
- Docker organization (dev/prod configs)

**UNIKAMY**:

- Over-engineering (za du≈ºo mikroservis√≥w)
- Complex event flows
- External dependencies lock-in

## Struktura dokumentacji

```
/architektura_systemu.md     # G≈Ç√≥wny dokument, fazy projektu
/CLAUDE.md                   # Zasady i wzorce projektu
/docs/TASK_TEMPLATE.md       # Szablon dekompozycji zada≈Ñ
/docs/faza-X-nazwa/*.md      # Dekompozycje zada≈Ñ per faza
/PROJECT_CONTEXT.md          # Ten plik
```

## Workflow wykonywania zada≈Ñ

### Development Flow
1. **Start**: Sprawd≈∫ aktualnƒÖ fazƒô w `architektura_systemu.md`
2. **Wybierz zadanie**: Znajd≈∫ [ ] checkbox (nieuko≈Ñczone)
3. **Otw√≥rz dekompozycjƒô**: Kliknij link "Szczeg√≥≈Çy ‚Üí"
4. **Wykonaj**: U≈ºyj `/nakurwiaj <numer_bloku>`
5. **Waliduj**: Po ka≈ºdym bloku - testy, metryki, git commit

### CI/CD Flow (OBOWIƒÑZKOWY od Fazy 1)
1. **Build**: Obrazy Docker budowane w GitHub Actions
2. **Registry**: Publikacja do ghcr.io/hretheum/detektr/
3. **Deploy**: Pull z registry na serwer Nebula (NIGDY build na produkcji!)
4. **Verify**: Health checks wszystkich serwis√≥w

```bash
# Pe≈Çny deployment
git push origin main  # ‚Üí Automatyczny build i deploy

# Manual deployment
./scripts/deploy-to-nebula.sh
```

## Kluczowe zasady

- **TDD zawsze** - test first, code second
- **Observability first** - tracing/metrics od poczƒÖtku
- **Container first** - wszystko w Dockerze
- **CI/CD first** - build w GitHub Actions, deploy z registry
- **Clean Architecture** - separacja warstw
- **Zadania atomowe** - max 3h na zadanie
- **No hardcoded secrets** - wszystko przez SOPS

## Bounded Contexts

1. **Frame Processing** - Capture, buffering, storage
2. **AI Detection** - Face, gesture, object recognition
3. **Home Automation** - HA integration, action execution

## Fazy projektu

- **Faza 0**: Dokumentacja i planowanie ‚úÖ
- **Faza 1**: Fundament z observability ‚úÖ (CI/CD + przyk≈Çadowe serwisy)
- **Faza 2**: Akwizycja i storage üöß (5/8 zada≈Ñ uko≈Ñczonych)
- **Faza 3**: AI services podstawy
- **Faza 4**: Integracja z Home Assistant
- **Faza 5**: Zaawansowane AI i voice
- **Faza 6**: Optymalizacja i refinement

## Porty serwis√≥w

- 8000: base-template ‚úÖ
- 8001: frame-tracking ‚úÖ
- 8002: frame-buffer ‚úÖ
- 8003: object-detection
- 8004: ha-bridge
- 8005: metadata-storage ‚úÖ
- 8006: face-recognition
- 8007: echo-service
- 8008: gpu-demo
- 8009: example-otel
- 8080: rtsp-capture ‚úÖ
- 8099: sample-processor ‚úÖ
- 6379: Redis ‚úÖ
- 5432: PostgreSQL ‚úÖ
- 6432: PGBouncer ‚úÖ
- 9090: Prometheus ‚úÖ
- 16686: Jaeger ‚úÖ
- 3000: Grafana ‚úÖ

## Gdzie szukaƒá czego

### G≈Ç√≥wna dokumentacja (NEW!)
- **Architektura**: `/docs/ARCHITECTURE.md` - jak dzia≈Ça system
- **Development**: `/docs/DEVELOPMENT.md` - jak rozwijaƒá projekt
- **Troubleshooting**: `/docs/TROUBLESHOOTING.md` - rozwiƒÖzywanie problem√≥w
- **Makefile Guide**: `/docs/MAKEFILE_GUIDE.md` - wszystkie komendy

### Deployment & Operations
- **Unified Deployment**: `/docs/deployment/unified-deployment.md` ‚≠ê
- **Deployment Script**: `/scripts/deploy.sh` - jeden skrypt dla wszystkich ≈õrodowisk
- **Runbooks**: `/docs/runbooks/` - procedury dla typowych operacji

### Konfiguracja
- **Environment configs**: `/docker/environments/` - konfiguracje per ≈õrodowisko
- **CI/CD workflows**: `/.github/workflows/` - 5 zoptymalizowanych workflows
- **Secrets**: `.env.sops` - zaszyfrowane SOPS

### Legacy (do wygaszenia)
- **Stare deployment docs**: `/docs/deployment/README.md`
- **Jak co≈õ zrobiƒá**: `/CLAUDE.md`
- **Co zrobiƒá**: `/architektura_systemu.md`

## Komendy projektu

### Quick Start (NEW!)
- `make setup` - inicjalizacja projektu dla nowego developera
- `make up` - start development environment
- `make deploy` - deploy to production
- `make help` - pokazuje wszystkie dostƒôpne komendy

### Development
- `make dev-up` - start z hot reload
- `make dev-logs SERVICE=name` - logi konkretnego serwisu
- `make dev-shell SVC=name` - shell do kontenera
- `make test` - uruchom wszystkie testy
- `make lint` - sprawd≈∫ jako≈õƒá kodu
- `make format` - formatuj kod

### Production
- `make prod-deploy` - deploy na produkcjƒô
- `make prod-status` - sprawd≈∫ status
- `make prod-verify` - weryfikuj health checks
- `make prod-logs` - poka≈º logi produkcyjne

### Deployment (NEW!)
- `./scripts/deploy.sh production deploy` - unified deployment
- `./scripts/deploy.sh production status` - check status
- `./scripts/deploy.sh production verify` - health checks
- `./scripts/deploy.sh production rollback` - rollback

### Utilities
- `make secrets-edit` - edycja sekret√≥w SOPS
- `make db-shell` - PostgreSQL CLI
- `make redis-cli` - Redis CLI
- `make clean-all` - wyczy≈õƒá wszystko

## Na co uwa≈ºaƒá

1. Blok 0 (Prerequisites) - ZAWSZE wykonaj pierwszy
2. Metryki sukcesu - ka≈ºde zadanie ma kryteria
3. Rollback plan - ka≈ºde zadanie mo≈ºna cofnƒÖƒá
4. API keys - NIGDY nie commituj do repo (u≈ºywaj SOPS!)
5. GPU memory - monitor u≈ºycie VRAM
6. CI/CD - NIGDY nie buduj obraz√≥w na produkcji
7. Registry - wszystkie obrazy z ghcr.io/hretheum/detektr/

## Status Fazy 1 (COMPLETED ‚úÖ)

### Zrealizowane komponenty:
- ‚úÖ Infrastruktura observability (Prometheus, Jaeger, Grafana)
- ‚úÖ CI/CD pipeline (GitHub Actions + GHCR)
- ‚úÖ Deployment automation (scripts/deploy-to-nebula.sh)
- ‚úÖ Example service z pe≈Çnym observability (example-otel)

## Status transformacji projektu (2025-07-24)

### ‚úÖ Faza 1: Unifikacja nazewnictwa (COMPLETED)
- Zmiana nazwy projektu: bezrobocie-detektor ‚Üí detektr
- Aktualizacja 42 plik√≥w (workflows, docker-compose, dokumentacja)
- Nowy registry path: ghcr.io/hretheum/detektr/
- Backup branch: naming-unification-backup-20250723-220210

### ‚úÖ Faza 2: Konsolidacja workflows (COMPLETED)
- Redukcja z 14 do 5 workflows (-64%)
- Nowe workflows:
  - main-pipeline.yml (g≈Ç√≥wny CI/CD)
  - pr-checks.yml (walidacja PR + testy)
  - manual-operations.yml (operacje manualne)
  - scheduled-tasks.yml (zadania cykliczne)
  - release.yml (bez zmian)
- Skrypt migracji: scripts/migrate-workflows.sh
- Dokumentacja: docs/WORKFLOW_CONSOLIDATION_PLAN.md

### ‚úÖ Faza 3: Reorganizacja Docker Compose (COMPLETED)
- Reorganizacja 16+ plik√≥w ‚Üí 8 plik√≥w w hierarchicznej strukturze
- Nowa struktura: docker/base, docker/environments, docker/features
- Convenience scripts: docker/dev.sh, docker/prod.sh, docker/test.sh
- Skrypt migracji: scripts/migrate-docker-compose.sh
- Pe≈Çna dokumentacja: docker/README.md

### ‚úÖ Faza 4: GHCR Cleanup (COMPLETED)
- Migracja 5 brakujƒÖcych obraz√≥w do ghcr.io/hretheum/detektr/*
- Usuniƒôcie przestarza≈Çych obraz√≥w consensus/*
- Automatyczny cleanup workflow (co niedzielƒô 4:00 UTC)
- Retention policy: 30 dni / 5 ostatnich wersji
- Workflow: .github/workflows/ghcr-cleanup.yml
- Raport: docs/PHASE4_GHCR_CLEANUP_REPORT.md

### ‚úÖ Faza 5: Deployment Automation (COMPLETED)
- Unified deployment script: scripts/deploy.sh
- Wsparcie dla 3 ≈õrodowisk: production, staging, local
- 7 akcji: deploy, status, logs, restart, stop, verify, cleanup
- Environment-specific configs w docker/environments/
- Integracja z GitHub Actions (main-pipeline.yml)
- Dokumentacja: docs/deployment/unified-deployment.md

### ‚úÖ Faza 6: Documentation (COMPLETED)
- Nowy README.md z 3 kluczowymi linkami
- docs/ARCHITECTURE.md - pe≈Çna architektura systemu
- docs/DEVELOPMENT.md - przewodnik developera
- docs/TROUBLESHOOTING.md - rozwiƒÖzywanie problem√≥w
- Runbooks w docs/runbooks/ dla typowych operacji
- docs/MAKEFILE_GUIDE.md - dokumentacja Makefile

### ‚úÖ Faza 7: Makefile Unification (COMPLETED)
- Unified Makefile z 50+ komendami
- Kategorie: Quick Start, Development, Production, Testing, etc.
- Inteligentna selekcja ≈õrodowisk (ENV variable)
- User-friendly help z opisami
- Aliasy dla popularnych komend (make up, make deploy)
- Pe≈Çna integracja z CI/CD

### Dokumentacja zaktualizowana:
- ‚úÖ CLAUDE.md - zawiera pe≈Çne CI/CD guidelines
- ‚úÖ docs/CI_CD_SETUP.md - instrukcje konfiguracji
- ‚úÖ docs/faza-1-fundament/99-deployment-remediation.md - strategia deployment

### Ready for Faza 2:
- Solidny fundament CI/CD
- Dzia≈ÇajƒÖce przyk≈Çady do kopiowania
- Pe≈Çna observability od poczƒÖtku
- Zautomatyzowany deployment

## Krytyczne problemy i rozwiƒÖzania

### Docker Compose - problem z wczytywaniem zmiennych ≈õrodowiskowych (2025-07-25)

**Problem**: Us≈Çugi (frame-tracking, base-template, metadata-storage) nie mog≈Çy po≈ÇƒÖczyƒá siƒô z PostgreSQL z b≈Çƒôdem "password authentication failed for user 'detektor'".

**Przyczyna**: Docker Compose nie wczytuje automatycznie pliku `.env` gdy u≈ºywane sƒÖ pe≈Çne ≈õcie≈ºki do plik√≥w compose (np. `-f /opt/detektor/docker/base/docker-compose.yml`). W rezultacie zmienna `POSTGRES_PASSWORD` by≈Ça pusta.

**RozwiƒÖzanie**: Dodanie `--env-file .env` do WSZYSTKICH wywo≈Ça≈Ñ `docker compose` w skrypcie `deploy.sh`:

```bash
# Niepoprawnie (nie dzia≈Ça z pe≈Çnymi ≈õcie≈ºkami):
docker compose "${COMPOSE_FILES[@]}" up -d

# Poprawnie (wymusza wczytanie .env):
docker compose --env-file .env "${COMPOSE_FILES[@]}" up -d
```

**Zakres zmian**:
- scripts/deploy.sh - 8 miejsc gdzie dodano `--env-file .env`
- .github/workflows/main-pipeline.yml - usuniƒôto domy≈õlne eksporty hase≈Ç, dodano kopiowanie istniejƒÖcego .env

**Lekcja**: Zawsze u≈ºywaj `--env-file .env` w skryptach deployment gdy u≈ºywasz pe≈Çnych ≈õcie≈ºek do plik√≥w docker-compose.

### 6. Frame Tracking - Dwa komponenty (2025-07-26)

**Problem**: PoczƒÖtkowo niejasne czy frame-tracking to serwis czy biblioteka.

**RozwiƒÖzanie**: Frame tracking sk≈Çada siƒô z DW√ìCH komponent√≥w:
1. **Frame-tracking SERVICE** (port 8081) - Event Sourcing dla audytu cyklu ≈ºycia klatek
2. **Frame-tracking LIBRARY** (services/shared/frame-tracking) - Distributed tracing z OpenTelemetry

**Implementacja biblioteki**:
- Zintegrowana w 4 serwisach: frame-buffer, base-processor, metadata-storage, sample-processor
- Automatyczna propagacja trace context przez Redis Streams i HTTP headers
- Graceful fallback gdy biblioteka niedostƒôpna
- Pe≈Çna widoczno≈õƒá w Jaeger UI

**Lekcja**: Rozr√≥≈ºniaj miƒôdzy serwisami infrastrukturalnymi (event sourcing) a bibliotekami wsp√≥≈Çdzielonymi (tracing).

## Status Fazy 2: Akwizycja i Storage (2025-07-26)

### ‚úÖ Uko≈Ñczone zadania (6/8):
1. **RTSP Capture Service** - Dzia≈ÇajƒÖcy na Nebula:8080, konfiguracja Reolink, status "degraded" (czeka na Redis)
2. **Frame Buffer z Redis** - Throughput 80k frames/s, latency 0.01ms, DLQ skonfigurowane
3. **Redis Configuration** - 4GB limit, persistence, monitoring, Telegram alerts
4. **PostgreSQL/TimescaleDB** - 100GB volume, PGBouncer, hypertables ready
5. **Frame Processor Base Service** - Framework w services/shared/base-processor/, sample-processor na Nebula:8099
6. **Frame tracking z distributed tracing** - Biblioteka w services/shared/frame-tracking, zintegrowana w 4 serwisach, trace propagation dzia≈Ça

### ‚è≥ W trakcie realizacji (0/8):
- Brak aktywnych zada≈Ñ

### üìã Do zrobienia (2/8):
7. Dashboard: Frame Pipeline Overview
8. Alerty: frame drop, latency, queue size

### üîß Dzia≈ÇajƒÖce us≈Çugi produkcyjne:
- **Infrastruktura**: postgres, pgbouncer, redis, prometheus, grafana, jaeger (wszystkie healthy)
- **Aplikacyjne**: rtsp-capture, frame-buffer, frame-tracking (jako serwis event sourcing), metadata-storage, base-template, sample-processor (wszystkie healthy)
- **Biblioteki**: frame-tracking (shared library) zintegrowana w: frame-buffer, base-processor, metadata-storage, sample-processor
- **≈ÅƒÖcznie**: 11 us≈Çug dzia≈ÇajƒÖcych na Nebula z pe≈Çnym monitoringiem i distributed tracing

## ‚úÖ ROZWIƒÑZANY PROBLEM: rtsp-capture nie odpowiada na HTTP (2025-07-26 23:20)

### Problem:
- **`cv2.VideoCapture.read()`** to synchroniczna funkcja kt√≥ra blokowa≈Ça event loop FastAPI
- Wszystkie HTTP requesty wisia≈Çy w niesko≈Ñczono≈õƒá mimo ≈ºe capture dzia≈Ça≈Ç

### RozwiƒÖzanie:
```python
# Zamiast:
ret, frame = self.cap.read()

# U≈ºywamy:
loop = asyncio.get_event_loop()
ret, frame = await loop.run_in_executor(None, self.cap.read)
```

### Dodatkowe poprawki:
- Wykomentowano `RedisInstrumentor().instrument()` w observability.py (mog≈Ço powodowaƒá problemy)
- Przeniesiono `init_telemetry()` do startup event (zamiast na poziomie modu≈Çu)

### Status: ‚úÖ DZIA≈ÅA
- rtsp-capture dzia≈Ça na porcie 8080
- ≈Åapie klatki z kamery Reolink (192.168.1.195)
- Publikuje metadata do Redis Streams
- Health endpoint `/health` odpowiada poprawnie
- Wszystkie metryki i monitoring dzia≈ÇajƒÖ
