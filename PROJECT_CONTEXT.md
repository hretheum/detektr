# Kontekst Projektu Detektor - dla LLM

<!--
META LLM PROMPT:
Ten plik sÅ‚uÅ¼y do szybkiego wprowadzenia LLM w kontekst projektu.
Wczytaj go na poczÄ…tku kaÅ¼dej nowej sesji/konwersacji.

WAÅ»NE: Po wczytaniu tego pliku, NATYCHMIAST wczytaj rÃ³wnieÅ¼ konfiguracje agentÃ³w:
- /Users/hretheum/dev/bezrobocie/detektor/.claude/agents/architecture-advisor.md
- /Users/hretheum/dev/bezrobocie/detektor/.claude/agents/code-reviewer.md
- /Users/hretheum/dev/bezrobocie/detektor/.claude/agents/debugger.md
- /Users/hretheum/dev/bezrobocie/detektor/.claude/agents/deployment-specialist.md
- /Users/hretheum/dev/bezrobocie/detektor/.claude/agents/pipeline-debugger.md
- /Users/hretheum/dev/bezrobocie/detektor/.claude/agents/detektor-coder.md
- /Users/hretheum/dev/bezrobocie/detektor/.claude/agents/documentation-keeper.md
- /Users/hretheum/dev/bezrobocie/detektor/.claude/agents/pisarz.md
-->

## O projekcie

**Nazwa**: System Detekcji i Automatyzacji Wizyjnej (Detektor)
**Repo**: github.com/hretheum/detektr
**Registry**: ghcr.io/hretheum/detektr/
**Typ**: Projekt hobbystyczny
**Cel**: Przechwytywanie obrazu z kamery IP + AI rozpoznawanie + automatyzacja Home Assistant

## Stack technologiczny

- **Serwer**: Ubuntu z GTX 4070 Super (16GB VRAM), i7, 64GB RAM (hostname: nebula)
- **Infrastruktura**: Docker, Docker Compose, container-first
- **CI/CD**: GitHub Actions + GitHub Container Registry (ghcr.io)
- **JÄ™zyki**: Python 3.11+, FastAPI
- **AI/ML**: YOLO, MediaPipe, Whisper, OpenAI/Anthropic API
- **Observability**: Jaeger, Prometheus, Grafana (od poczÄ…tku!)
- **Architektura**: Clean Architecture, DDD, Event Sourcing, TDD
- **Message Bus**: Redis Streams (adoptowane z eofek/detektor)
- **Secrets**: SOPS z age encryption

## Influences - eofek/detektor Analysis

**Reference**: `docs/analysis/eofek-detektor-analysis.md`
**Source Repository**: <https://github.com/eofek/detektor> (wÅ‚asnoÅ›Ä‡ autora - kod dostÄ™pny do wykorzystania)

**ADOPTUJEMY**:

- Metrics abstraction layer pattern
- Redis Streams event-driven architecture
- GPU monitoring patterns
- Docker organization (dev/prod configs)

**UNIKAMY**:

- Over-engineering (za duÅ¼o mikroservisÃ³w)
- Complex event flows
- External dependencies lock-in

## Struktura dokumentacji

```
/architektura_systemu.md     # GÅ‚Ã³wny dokument, fazy projektu
/CLAUDE.md                   # Zasady i wzorce projektu
/docs/TASK_TEMPLATE.md       # Szablon dekompozycji zadaÅ„
/docs/faza-X-nazwa/*.md      # Dekompozycje zadaÅ„ per faza
/PROJECT_CONTEXT.md          # Ten plik
```

## Workflow wykonywania zadaÅ„ - Automatyczny Å‚aÅ„cuch agentÃ³w

### Development Flow
1. **Start**: SprawdÅº aktualnÄ… fazÄ™ w `architektura_systemu.md`
2. **Wybierz zadanie**: ZnajdÅº [ ] checkbox (nieukoÅ„czone)
3. **OtwÃ³rz dekompozycjÄ™**: Kliknij link "SzczegÃ³Å‚y â†’"
4. **Wykonaj**: UÅ¼yj `/nakurwiaj <numer_bloku>`
5. **Code Review**: Po KAÅ»DYM zadaniu atomowym uruchom `/agent code-reviewer`
6. **Waliduj**: Po kaÅ¼dym bloku - testy, metryki, git commit

### ReguÅ‚y generalne dla /nakurwiaj - Automatyczny Å‚aÅ„cuch agentÃ³w

Gdy LLM otrzymuje komendÄ™ `/nakurwiaj`, automatycznie stosuje nastÄ™pujÄ…cy Å‚aÅ„cuch:

#### 1. Analiza kontekstu zadania
```
IF task contains "implement|create|add|napisz|stwÃ³rz|dodaj":
    â†’ /agent detektor-coder
ELIF task contains "debug|fix|investigate|napraw|zbadaj":
    â†’ /agent debugger lub pipeline-debugger
ELIF task contains "refactor|optimize|zoptymalizuj":
    â†’ /agent architecture-advisor â†’ detektor-coder
ELIF task contains "deploy|deployment|wdrÃ³Å¼":
    â†’ /agent deployment-specialist
```

#### 2. Quality Gate (ZAWSZE po kaÅ¼dym zadaniu)
```
AFTER each atomic task:
    â†’ /agent code-reviewer
    IF critical_issues:
        â†’ Loop back to previous agent with feedback
        â†’ Maximum 3 iterations
        â†’ Auto-fix issues without asking
```

#### 3. Deployment Flow (warunkowy)
```
IF block contains deployment tasks OR "CI/CD" OR "GitHub Actions":
    â†’ git add -A && git commit -m "feat: [nazwa bloku]"
    â†’ git push origin main (triggers CI/CD)
    â†’ /agent deployment-specialist (monitor pipeline)
    â†’ Verify health checks on Nebula
    â†’ IF failed: automatic rollback + debug
```

#### 3.5. Documentation Sync (ZAWSZE przed przejÅ›ciem do kolejnego bloku)
```
BEFORE moving to next block:
    â†’ /agent documentation-keeper
    â†’ Synchronize:
        - Task checkboxes [x] in decomposition files
        - Service ports in PROJECT_CONTEXT.md
        - Status in architektura_systemu.md
        - New problems in TROUBLESHOOTING.md
        - Service READMEs if new services added
    â†’ Verify all docs are consistent
```

#### 4. Automatyzacja i autonomia
- âœ… Automatyczne commity z descriptive messages (format: "feat: [task name]" lub "fix: [issue]")
- âœ… Automatyczny push (chyba Å¼e user explicite mÃ³wi "bez push" lub "no push")
- âœ… Kontynuacja do nastÄ™pnego bloku (chyba Å¼e user mÃ³wi "tylko ten blok" lub "only this block")
- âœ… Brak pytaÅ„ o potwierdzenie - peÅ‚ne zaufanie do agentÃ³w i ich decyzji
- âœ… Automatyczne naprawianie bÅ‚Ä™dÃ³w znalezionych przez code-reviewer
- âœ… UÅ¼ywanie wielu agentÃ³w rÃ³wnolegle gdy to moÅ¼liwe

#### 5. PrzykÅ‚ad peÅ‚nego flow
```
User: /nakurwiaj blok-1

LLM:
[Blok 1/N] Frame Processor Implementation
=========================================

[Zadanie 1/3] "Implement RTSP capture service"
â†’ WywoÅ‚ujÄ™: /agent detektor-coder
  âœ“ Created: services/rtsp-capture/
  âœ“ Tests: 15/15 passing
â†’ WywoÅ‚ujÄ™: /agent code-reviewer
  ! Found 2 issues - auto-fixing...
â†’ WywoÅ‚ujÄ™: /agent detektor-coder --fix
  âœ“ Issues resolved
â†’ WywoÅ‚ujÄ™: /agent code-reviewer
  âœ“ Code approved

[Zadanie 2/3] "Add distributed tracing"
â†’ WywoÅ‚ujÄ™: /agent detektor-coder --feature=tracing
  âœ“ OpenTelemetry integrated
  âœ“ Trace context propagation added
â†’ WywoÅ‚ujÄ™: /agent code-reviewer
  âœ“ No issues found

[Zadanie 3/3] "Deploy to production"
â†’ Executing: git add -A && git commit -m "feat: rtsp-capture service with distributed tracing"
â†’ Executing: git push origin main
â†’ WywoÅ‚ujÄ™: /agent deployment-specialist
  âœ“ CI/CD pipeline passed
  âœ“ Health check: http://nebula:8080/health - OK
  âœ“ Metrics endpoint verified

â†’ WywoÅ‚ujÄ™: /agent documentation-keeper
  âœ“ Updated PROJECT_CONTEXT.md - service ports
  âœ“ Updated architektura_systemu.md - task checkboxes
  âœ“ Synced README.md - service list
  âœ“ All documentation consistent

Blok 1 completed successfully. Proceeding to Blok 2...
```

#### 6. Specjalne przypadki
- **BÅ‚Ä…d w pipeline**: Automatyczny rollback, nastÄ™pnie `/agent debugger` â†’ napraw â†’ ponÃ³w deployment
- **Test failures**: `/agent detektor-coder --fix-tests` â†’ re-run tests â†’ proceed
- **Performance issues**: `/agent architecture-advisor` â†’ recommendations â†’ `/agent detektor-coder` â†’ implement
- **Brak dostÄ™pu/credentials**: Pause â†’ inform user â†’ wait for fix â†’ resume

### CI/CD Flow (OBOWIÄ„ZKOWY od Fazy 1)
1. **Build**: Obrazy Docker budowane w GitHub Actions
2. **Registry**: Publikacja do ghcr.io/hretheum/detektr/
3. **Deploy**: Pull z registry na serwer Nebula (NIGDY build na produkcji!)
4. **Verify**: Health checks wszystkich serwisÃ³w

```bash
# PeÅ‚ny deployment
git push origin main  # â†’ Automatyczny build i deploy

# Manual deployment
./scripts/deploy-to-nebula.sh
```

## Kluczowe zasady

- **TDD zawsze** - test first, code second
- **Observability first** - tracing/metrics od poczÄ…tku
- **Container first** - wszystko w Dockerze
- **CI/CD first** - build w GitHub Actions, deploy z registry
- **Clean Architecture** - separacja warstw
- **Zadania atomowe** - max 3h na zadanie
- **Code Review OBOWIÄ„ZKOWY** - po kaÅ¼dym zadaniu atomowym `/agent code-reviewer`
- **No hardcoded secrets** - wszystko przez SOPS

## Bounded Contexts

1. **Frame Processing** - Capture, buffering, storage
2. **AI Detection** - Face, gesture, object recognition
3. **Home Automation** - HA integration, action execution

## Fazy projektu

- **Faza 0**: Dokumentacja i planowanie âœ…
- **Faza 1**: Fundament z observability âœ… (CI/CD + przykÅ‚adowe serwisy)
- **Faza 2**: Akwizycja i storage ğŸš§ (5/8 zadaÅ„ ukoÅ„czonych)
- **Faza 3**: AI services podstawy
- **Faza 4**: Integracja z Home Assistant
- **Faza 5**: Zaawansowane AI i voice
- **Faza 6**: Optymalizacja i refinement

## DostÄ™pne Sub-Agenty (AI Assistants)

Projekt posiada 8 wyspecjalizowanych agentÃ³w pomocniczych:

1. **`/agent architecture-advisor`** - Ekspert od Clean Architecture, DDD, wzorcÃ³w projektowych
2. **`/agent code-reviewer`** - Code review, refaktoring, best practices (OBOWIÄ„ZKOWY po kaÅ¼dym zadaniu atomowym!)
3. **`/agent debugger`** - Troubleshooting, analiza logÃ³w, debugging runtime
4. **`/agent deployment-specialist`** - CI/CD, Docker, GitHub Actions, deployment na Nebula
5. **`/agent pipeline-debugger`** - Dedykowany dla problemÃ³w w pipeline przetwarzania klatek
6. **`/agent detektor-coder`** - Implementacja zadaÅ„ atomowych, TDD, observability-first
7. **`/agent documentation-keeper`** - Synchronizacja dokumentacji, aktualizacja statusÃ³w (URUCHAMIANY przed przejÅ›ciem do kolejnego bloku)
8. **`/agent pisarz`** - Zbiera materiaÅ‚y do tech deep dives na social media (zapisuje w /socmedia/)

Konfiguracje agentÃ³w znajdujÄ… siÄ™ w: `/Users/hretheum/dev/bezrobocie/detektor/.claude/agents/`

## Porty serwisÃ³w

- 8000: base-template âœ…
- 8001: frame-tracking âœ…
- 8002: frame-buffer âœ…
- 8003: object-detection
- 8004: ha-bridge
- 8005: metadata-storage âœ…
- 8006: face-recognition
- 8007: echo-service
- 8008: gpu-demo
- 8009: example-otel
- 8080: rtsp-capture âœ…
- 8099: sample-processor âœ…
- 6379: Redis âœ…
- 5432: PostgreSQL âœ…
- 6432: PGBouncer âœ…
- 9090: Prometheus âœ…
- 16686: Jaeger âœ…
- 3000: Grafana âœ…

## Gdzie szukaÄ‡ czego

### GÅ‚Ã³wna dokumentacja (NEW!)
- **Architektura**: `/docs/ARCHITECTURE.md` - jak dziaÅ‚a system
- **Development**: `/docs/DEVELOPMENT.md` - jak rozwijaÄ‡ projekt
- **Troubleshooting**: `/docs/TROUBLESHOOTING.md` - rozwiÄ…zywanie problemÃ³w
- **Makefile Guide**: `/docs/MAKEFILE_GUIDE.md` - wszystkie komendy

### Deployment & Operations
- **Unified Deployment**: `/docs/deployment/unified-deployment.md` â­
- **Deployment Script**: `/scripts/deploy.sh` - jeden skrypt dla wszystkich Å›rodowisk
- **Runbooks**: `/docs/runbooks/` - procedury dla typowych operacji

### Konfiguracja
- **Environment configs**: `/docker/environments/` - konfiguracje per Å›rodowisko
- **CI/CD workflows**: `/.github/workflows/` - 5 zoptymalizowanych workflows
- **Secrets**: `.env.sops` - zaszyfrowane SOPS

### Legacy (do wygaszenia)
- **Stare deployment docs**: `/docs/deployment/README.md`
- **Jak coÅ› zrobiÄ‡**: `/CLAUDE.md`
- **Co zrobiÄ‡**: `/architektura_systemu.md`

## Komendy projektu

### Quick Start (NEW!)
- `make setup` - inicjalizacja projektu dla nowego developera
- `make up` - start development environment
- `make deploy` - deploy to production
- `make help` - pokazuje wszystkie dostÄ™pne komendy

### Development
- `make dev-up` - start z hot reload
- `make dev-logs SERVICE=name` - logi konkretnego serwisu
- `make dev-shell SVC=name` - shell do kontenera
- `make test` - uruchom wszystkie testy
- `make lint` - sprawdÅº jakoÅ›Ä‡ kodu
- `make format` - formatuj kod

### Production
- `make prod-deploy` - deploy na produkcjÄ™
- `make prod-status` - sprawdÅº status
- `make prod-verify` - weryfikuj health checks
- `make prod-logs` - pokaÅ¼ logi produkcyjne

### Deployment (NEW!)
- `./scripts/deploy.sh production deploy` - unified deployment
- `./scripts/deploy.sh production status` - check status
- `./scripts/deploy.sh production verify` - health checks
- `./scripts/deploy.sh production rollback` - rollback

### Utilities
- `make secrets-edit` - edycja sekretÃ³w SOPS
- `make db-shell` - PostgreSQL CLI
- `make redis-cli` - Redis CLI
- `make clean-all` - wyczyÅ›Ä‡ wszystko

## Na co uwaÅ¼aÄ‡

1. Blok 0 (Prerequisites) - ZAWSZE wykonaj pierwszy
2. Metryki sukcesu - kaÅ¼de zadanie ma kryteria
3. Rollback plan - kaÅ¼de zadanie moÅ¼na cofnÄ…Ä‡
4. API keys - NIGDY nie commituj do repo (uÅ¼ywaj SOPS!)
5. GPU memory - monitor uÅ¼ycie VRAM
6. CI/CD - NIGDY nie buduj obrazÃ³w na produkcji
7. Registry - wszystkie obrazy z ghcr.io/hretheum/detektr/

## Status Fazy 1 (COMPLETED âœ…)

### Zrealizowane komponenty:
- âœ… Infrastruktura observability (Prometheus, Jaeger, Grafana)
- âœ… CI/CD pipeline (GitHub Actions + GHCR)
- âœ… Deployment automation (scripts/deploy-to-nebula.sh)
- âœ… Example service z peÅ‚nym observability (example-otel)

## Status transformacji projektu (2025-07-24)

### âœ… Faza 1: Unifikacja nazewnictwa (COMPLETED)
- Zmiana nazwy projektu: bezrobocie-detektor â†’ detektr
- Aktualizacja 42 plikÃ³w (workflows, docker-compose, dokumentacja)
- Nowy registry path: ghcr.io/hretheum/detektr/
- Backup branch: naming-unification-backup-20250723-220210

### âœ… Faza 2: Konsolidacja workflows (COMPLETED)
- Redukcja z 14 do 5 workflows (-64%)
- Nowe workflows:
  - main-pipeline.yml (gÅ‚Ã³wny CI/CD)
  - pr-checks.yml (walidacja PR + testy)
  - manual-operations.yml (operacje manualne)
  - scheduled-tasks.yml (zadania cykliczne)
  - release.yml (bez zmian)
- Skrypt migracji: scripts/migrate-workflows.sh
- Dokumentacja: docs/WORKFLOW_CONSOLIDATION_PLAN.md

### âœ… Faza 3: Reorganizacja Docker Compose (COMPLETED)
- Reorganizacja 16+ plikÃ³w â†’ 8 plikÃ³w w hierarchicznej strukturze
- Nowa struktura: docker/base, docker/environments, docker/features
- Convenience scripts: docker/dev.sh, docker/prod.sh, docker/test.sh
- Skrypt migracji: scripts/migrate-docker-compose.sh
- PeÅ‚na dokumentacja: docker/README.md

### âœ… Faza 4: GHCR Cleanup (COMPLETED)
- Migracja 5 brakujÄ…cych obrazÃ³w do ghcr.io/hretheum/detektr/*
- UsuniÄ™cie przestarzaÅ‚ych obrazÃ³w consensus/*
- Automatyczny cleanup workflow (co niedzielÄ™ 4:00 UTC)
- Retention policy: 30 dni / 5 ostatnich wersji
- Workflow: .github/workflows/ghcr-cleanup.yml
- Raport: docs/PHASE4_GHCR_CLEANUP_REPORT.md

### âœ… Faza 5: Deployment Automation (COMPLETED)
- Unified deployment script: scripts/deploy.sh
- Wsparcie dla 3 Å›rodowisk: production, staging, local
- 7 akcji: deploy, status, logs, restart, stop, verify, cleanup
- Environment-specific configs w docker/environments/
- Integracja z GitHub Actions (main-pipeline.yml)
- Dokumentacja: docs/deployment/unified-deployment.md

### âœ… Faza 6: Documentation (COMPLETED)
- Nowy README.md z 3 kluczowymi linkami
- docs/ARCHITECTURE.md - peÅ‚na architektura systemu
- docs/DEVELOPMENT.md - przewodnik developera
- docs/TROUBLESHOOTING.md - rozwiÄ…zywanie problemÃ³w
- Runbooks w docs/runbooks/ dla typowych operacji
- docs/MAKEFILE_GUIDE.md - dokumentacja Makefile

### âœ… Faza 7: Makefile Unification (COMPLETED)
- Unified Makefile z 50+ komendami
- Kategorie: Quick Start, Development, Production, Testing, etc.
- Inteligentna selekcja Å›rodowisk (ENV variable)
- User-friendly help z opisami
- Aliasy dla popularnych komend (make up, make deploy)
- PeÅ‚na integracja z CI/CD

### Dokumentacja zaktualizowana:
- âœ… CLAUDE.md - zawiera peÅ‚ne CI/CD guidelines
- âœ… docs/CI_CD_SETUP.md - instrukcje konfiguracji
- âœ… docs/faza-1-fundament/99-deployment-remediation.md - strategia deployment

### Ready for Faza 2:
- Solidny fundament CI/CD
- DziaÅ‚ajÄ…ce przykÅ‚ady do kopiowania
- PeÅ‚na observability od poczÄ…tku
- Zautomatyzowany deployment

## Krytyczne problemy i rozwiÄ…zania

### Docker Compose - problem z wczytywaniem zmiennych Å›rodowiskowych (2025-07-25)

**Problem**: UsÅ‚ugi (frame-tracking, base-template, metadata-storage) nie mogÅ‚y poÅ‚Ä…czyÄ‡ siÄ™ z PostgreSQL z bÅ‚Ä™dem "password authentication failed for user 'detektor'".

**Przyczyna**: Docker Compose nie wczytuje automatycznie pliku `.env` gdy uÅ¼ywane sÄ… peÅ‚ne Å›cieÅ¼ki do plikÃ³w compose (np. `-f /opt/detektor/docker/base/docker-compose.yml`). W rezultacie zmienna `POSTGRES_PASSWORD` byÅ‚a pusta.

**RozwiÄ…zanie**: Dodanie `--env-file .env` do WSZYSTKICH wywoÅ‚aÅ„ `docker compose` w skrypcie `deploy.sh`:

```bash
# Niepoprawnie (nie dziaÅ‚a z peÅ‚nymi Å›cieÅ¼kami):
docker compose "${COMPOSE_FILES[@]}" up -d

# Poprawnie (wymusza wczytanie .env):
docker compose --env-file .env "${COMPOSE_FILES[@]}" up -d
```

**Zakres zmian**:
- scripts/deploy.sh - 8 miejsc gdzie dodano `--env-file .env`
- .github/workflows/main-pipeline.yml - usuniÄ™to domyÅ›lne eksporty haseÅ‚, dodano kopiowanie istniejÄ…cego .env

**Lekcja**: Zawsze uÅ¼ywaj `--env-file .env` w skryptach deployment gdy uÅ¼ywasz peÅ‚nych Å›cieÅ¼ek do plikÃ³w docker-compose.

### 6. Frame Tracking - Dwa komponenty (2025-07-26)

**Problem**: PoczÄ…tkowo niejasne czy frame-tracking to serwis czy biblioteka.

**RozwiÄ…zanie**: Frame tracking skÅ‚ada siÄ™ z DWÃ“CH komponentÃ³w:
1. **Frame-tracking SERVICE** (port 8081) - Event Sourcing dla audytu cyklu Å¼ycia klatek
2. **Frame-tracking LIBRARY** (services/shared/frame-tracking) - Distributed tracing z OpenTelemetry

**Implementacja biblioteki**:
- Zintegrowana w 4 serwisach: frame-buffer, base-processor, metadata-storage, sample-processor
- Automatyczna propagacja trace context przez Redis Streams i HTTP headers
- Graceful fallback gdy biblioteka niedostÄ™pna
- PeÅ‚na widocznoÅ›Ä‡ w Jaeger UI

**Lekcja**: RozrÃ³Å¼niaj miÄ™dzy serwisami infrastrukturalnymi (event sourcing) a bibliotekami wspÃ³Å‚dzielonymi (tracing).

## Status Fazy 2: Akwizycja i Storage (2025-01-27)

### âœ… UkoÅ„czone zadania (6/8):
1. **RTSP Capture Service** - DziaÅ‚ajÄ…cy na Nebula:8080, generuje FrameID, publikuje do Redis Stream
2. **Frame Buffer z Redis** - Consumer dziaÅ‚a, ale architektura niekompletna (dead-end)
3. **Redis Configuration** - 4GB limit, persistence, monitoring, Telegram alerts
4. **PostgreSQL/TimescaleDB** - 100GB volume, PGBouncer, hypertables ready
5. **Frame Processor Base Service** - Framework w services/shared/base-processor/, sample-processor na Nebula:8099
6. **Frame tracking z distributed tracing** - Biblioteka frame-tracking zintegrowana, ale brak peÅ‚nego flow

### â³ W trakcie realizacji (0/8):
- Brak aktywnych zadaÅ„

### ğŸ“‹ Do zrobienia (2/8):
7. Dashboard: Frame Pipeline Overview
8. Alerty: frame drop, latency, queue size

### ğŸš¨ Krytyczne problemy architekturalne (2025-01-27):
1. **Frame Buffer Dead-End**:
   - Consumer pobiera z Redis Stream â†’ buforuje w pamiÄ™ci â†’ âŒ nikt nie konsumuje
   - Buffer siÄ™ zapeÅ‚nia (1000 klatek) i zaczyna odrzucaÄ‡ wszystkie nowe
   - Brak konfiguracji procesorÃ³w do pobierania z frame-buffer API
   - Skutek: 100% frame loss po zapeÅ‚nieniu bufora

2. **Niekompletny pipeline**:
   - Oczekiwany: RTSP â†’ Redis â†’ Frame Buffer â†’ Processors â†’ Storage
   - Rzeczywisty: RTSP â†’ Redis â†’ Frame Buffer â†’ âŒ (Å›lepa uliczka)
   - Sample-processor nie jest skonfigurowany do pobierania z frame-buffer

3. **Trace propagation niepeÅ‚na**:
   - rtsp-capture: âœ… generuje FrameID i trace
   - frame-buffer: âœ… propaguje trace context (z TraceContext.inject)
   - processors: âŒ nie pobierajÄ… klatek wiÄ™c nie ma dalszej propagacji
   - metadata-storage: âœ… gotowy ale nie otrzymuje danych

### ğŸ”§ DziaÅ‚ajÄ…ce usÅ‚ugi produkcyjne:
- **Infrastruktura**: postgres, pgbouncer, redis, prometheus, grafana, jaeger (wszystkie healthy)
- **Aplikacyjne**: rtsp-capture, frame-buffer (z consumer), frame-events, metadata-storage, base-template, sample-processor
- **SieÄ‡**: Wszystkie serwisy na jednej sieci `detektor-network` (naprawiono problem z `detektr_default`)
- **Frame-buffer consumer**: Konsumuje ~1000 frames/sec ale buffer siÄ™ zapycha

## âœ… ROZWIÄ„ZANY PROBLEM: rtsp-capture nie odpowiada na HTTP (2025-07-26 23:20)

### Problem:
- **`cv2.VideoCapture.read()`** to synchroniczna funkcja ktÃ³ra blokowaÅ‚a event loop FastAPI
- Wszystkie HTTP requesty wisiaÅ‚y w nieskoÅ„czonoÅ›Ä‡ mimo Å¼e capture dziaÅ‚aÅ‚

### RozwiÄ…zanie:
```python
# Zamiast:
ret, frame = self.cap.read()

# UÅ¼ywamy:
loop = asyncio.get_event_loop()
ret, frame = await loop.run_in_executor(None, self.cap.read)
```

### Dodatkowe poprawki:
- Wykomentowano `RedisInstrumentor().instrument()` w observability.py (mogÅ‚o powodowaÄ‡ problemy)
- Przeniesiono `init_telemetry()` do startup event (zamiast na poziomie moduÅ‚u)

### Status: âœ… DZIAÅA
- rtsp-capture dziaÅ‚a na porcie 8080
- Åapie klatki z kamery Reolink (192.168.1.195)
- Publikuje metadata do Redis Streams
- Health endpoint `/health` odpowiada poprawnie
- Wszystkie metryki i monitoring dziaÅ‚ajÄ…
