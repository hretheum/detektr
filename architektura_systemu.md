# Detektor - System Detekcji i Automatyzacji Wizyjnej

<!--
LLM CONTEXT PROMPT:
To jest gÅ‚Ã³wny dokument architektury systemu detekcji wizyjnej.
Nazwa: Detektor (wczeÅ›niej: bezrobocie-detektor)
Repo: github.com/hretheum/detektr
Registry: ghcr.io/hretheum/detektr/
Projekt: Hobbystyczny system rozpoznawania obrazu z kamery IP + automatyzacja Home Assistant
Stack: Docker, Python, GPU (GTX 4070 Super), observability-first approach
Fazy: 0-6, kaÅ¼da z zadaniami zdekomponowanymi na bloki i zadania atomowe

INSPIRACJE: Bazujemy na proven patterns z eofek/detektor (docs/analysis/eofek-detektor-analysis.md):
- Source: https://github.com/eofek/detektor (repozytorium autorskie - kod dostÄ™pny)
- Metrics architecture pattern z abstraction layer
- Event-driven communication przez Redis Streams
- GPU monitoring patterns
- Error handling (Circuit Breaker, Adaptive Backoff)
- Ale UNIKAMY: over-engineering, microservices complexity, external lock-in

STATUS (2025-07-24):
âœ… Faza 0: Infrastruktura ukoÅ„czona (observability, CI/CD)
âœ… Faza 1: W trakcie (serwisy podstawowe)
âœ… Transformacja systemu - WSZYSTKIE FAZY UKOÅƒCZONE:
  - Faza 1: Unifikacja nazewnictwa â†’ detektr (42 pliki)
  - Faza 2: Konsolidacja workflows: 14 â†’ 5 plikÃ³w (-64%)
  - Faza 3: Reorganizacja Docker Compose: 16+ â†’ 8 plikÃ³w
  - Faza 4: GHCR Cleanup + automatyzacja (weekly cleanup)
  - Faza 5: Deployment Automation - unified script dla wszystkich Å›rodowisk
  - Faza 6: Documentation - kompletna dokumentacja projektu
  - Faza 7: Makefile Unification - 50+ komend, jeden interfejs
ğŸ‰ WSZYSTKIE METRYKI SUKCESU OSIÄ„GNIÄ˜TE!

Gdy rozpoczynasz pracÄ™ w dowolnym punkcie projektu:
1. SprawdÅº w ktÃ³rej fazie jesteÅ›my (zobacz sekcjÄ™ 2)
2. KaÅ¼de zadanie ma link do szczegÃ³Å‚owej dekompozycji
3. Stosuj TDD, Clean Architecture, observability od poczÄ…tku
4. UÅ¼ywaj CLAUDE.md dla zasad projektu
5. Implementuj patterns z eofek/detektor analysis gdzie wskazane
-->

## 1. Architektura RozwiÄ…zania

### 1.1 PrzeglÄ…d Systemu

System skÅ‚ada siÄ™ z nastÄ™pujÄ…cych gÅ‚Ã³wnych komponentÃ³w:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Kamera IP    â”‚â”€â”€â”€â”€â–¶â”‚   Serwer Ubuntu      â”‚â”€â”€â”€â”€â–¶â”‚ Home Assistant  â”‚
â”‚   (PoE)        â”‚     â”‚   GTX 4070 Super     â”‚     â”‚   (Ubuntu)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚   i7 + 64GB RAM      â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                                   â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚   UsÅ‚ugi Chmurowe    â”‚
                        â”‚   (LLM API)          â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 Komponenty Systemu

#### 1.2.1 Warstwa Akwizycji Obrazu

- **RTSP Stream Capture Service**: Kontener odbierajÄ…cy strumieÅ„ z kamery IP
- **Frame Buffer**: Redis/RabbitMQ do kolejkowania klatek do przetwarzania
- **Metadata Store**: PostgreSQL/TimescaleDB do przechowywania metadanych klatek

#### 1.2.2 Warstwa Przetwarzania AI

- **Face Recognition Service**: MediaPipe Face Detection + InsightFace embeddings (proven pattern z eofek/detektor)
- **Object Detection Service**: YOLO v8 (rozszerzenie wzglÄ™dem eofek/detektor)
- **Gesture Detection Service**: MediaPipe Hands + custom gesture recognition
- **Voice Processing Service**: Whisper (STT) + TTS

#### 1.2.3 Warstwa Integracji

- **Event Bus**: Redis Streams z event acknowledgement (pattern z eofek/detektor)
- **Intent Recognition Service**: PoÅ‚Ä…czenie z LLM (OpenAI/Anthropic)
- **Home Assistant Bridge**: MQTT/REST API (rozszerzenie - czego brakuje w eofek/detektor)
- **Metrics Adapter**: Abstraction layer dla Prometheus (adoptowane z eofek/detektor)

#### 1.2.4 Warstwa Observability

- **Distributed Tracing**: Jaeger
- **Metrics**: Prometheus + Grafana
- **Logging**: ELK Stack (Elasticsearch, Logstash, Kibana)
- **Frame Tracking**: Custom tracking ID dla kaÅ¼dej klatki

### 1.3 Architektura Kontenerowa

```yaml
# docker-compose.yml (uproszczony schemat)
version: '3.8'

services:
  # Akwizycja
  rtsp-capture:
    build: ./services/rtsp-capture
    environment:
      - CAMERA_IP=${CAMERA_IP}
      - FRAME_RATE=10
    volumes:
      - frame-storage:/data/frames

  # Kolejka
  redis:
    image: redis:alpine

  # Baza danych
  postgres:
    image: timescale/timescaledb:latest-pg15

  # AI Services
  face-recognition:
    build: ./services/face-recognition
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all

  gesture-detection:
    build: ./services/gesture-detection
    runtime: nvidia

  # Integracja
  mqtt-broker:
    image: eclipse-mosquitto

  # Observability
  jaeger:
    image: jaegertracing/all-in-one

  prometheus:
    image: prom/prometheus

  grafana:
    image: grafana/grafana
```

### 1.4 Flow Danych

1. **Capture**: Kamera IP â†’ RTSP Service â†’ Frame Buffer
2. **Process**: Frame Buffer â†’ AI Services â†’ Event Bus
3. **Analyze**: Event Bus â†’ Intent Recognition â†’ Action Queue
4. **Execute**: Action Queue â†’ HA Bridge â†’ Home Assistant
5. **Monitor**: KaÅ¼dy krok â†’ Jaeger/Prometheus â†’ Dashboards

#### Observability First Approach

KaÅ¼dy nowy serwis implementowany jest wedÅ‚ug wzorca:

```python
# base_service.py - szablon dla kaÅ¼dego serwisu
from opentelemetry import trace, metrics
from opentelemetry.instrumentation.logging import LoggingInstrumentor

class BaseService:
    def __init__(self, service_name: str):
        self.tracer = trace.get_tracer(service_name)
        self.meter = metrics.get_meter(service_name)
        self.logger = self._setup_logging(service_name)

        # Automatyczne metryki
        self.request_counter = self.meter.create_counter(
            f"{service_name}_requests_total"
        )
        self.latency_histogram = self.meter.create_histogram(
            f"{service_name}_latency_seconds"
        )

    @traced  # Decorator automatycznie dodajÄ…cy span
    async def process_frame(self, frame_id: str):
        # Logika przetwarzania z automatycznym tracingiem
        pass
```

### 1.5 Tracking Klatek

KaÅ¼da klatka otrzymuje unikalny UUID przy wejÅ›ciu do systemu:

```
frame_id: {timestamp}_{camera_id}_{sequence_number}
```

Metadane klatki:

- Timestamp akwizycji
- Status przetwarzania
- Wykryte obiekty/twarze/gesty
- PodjÄ™te akcje
- Czas przetwarzania na kaÅ¼dym etapie

## 2. Etapy Realizacji Projektu

<!--
LLM NAVIGATION PROMPT:
KaÅ¼da faza ma zadania z linkami do dekompozycji.
Status projektu sprawdÅº w:
- [ ] checkbox = zadanie do zrobienia
- [x] checkbox = zadanie ukoÅ„czone

Workflow dla nowego zadania:
1. OtwÃ³rz link "SzczegÃ³Å‚y â†’" przy zadaniu
2. UÅ¼yj komendy /nakurwiaj <numer_bloku> do automatycznego wykonania
3. Po kaÅ¼dym bloku zadaÅ„: walidacja, code review, git commit

WAÅ»NE: Zawsze zaczynaj od Bloku 0 (Prerequisites) w kaÅ¼dym zadaniu!
-->

### Faza 0: Dokumentacja i Planowanie (1-2 tygodnie)

#### Zadania i Metryki

1. **[x] Analiza i dokumentacja wymagaÅ„**
   - **Metryki**:
     - 100% wymagaÅ„ funkcjonalnych z ID i priorytetem
     - 100% wymagaÅ„ niefunkcjonalnych zmapowanych
     - Macierz Å›ledzenia wymagaÅ„ utworzona
   - **Walidacja**:

     ```bash
     # Sprawdzenie kompletnoÅ›ci
     grep -c "^- \*\*RF[0-9]\{3\}" docs/requirements/functional-requirements.md
     # Powinno zwrÃ³ciÄ‡ â‰¥20
     ```

   - **Sukces**: Wszystkie stakeholders zaakceptowali wymagania
   - **[SzczegÃ³Å‚y â†’](docs/faza-0-dokumentacja/01-analiza-wymagan.md)**

2. **[x] Utworzenie struktury projektu i repozytorium**
   - **Metryki**:
     - Struktura katalogÃ³w zgodna z Clean Architecture
     - CI/CD pipeline skonfigurowany
     - Pre-commit hooks dziaÅ‚ajÄ…
   - **Walidacja**:

     ```bash
     pre-commit run --all-files
     gh workflow list
     ```

   - **Sukces**: Pierwszy commit przechodzi przez CI
   - **[SzczegÃ³Å‚y â†’](docs/faza-0-dokumentacja/02-struktura-projektu.md)**

3. **[x] Dekompozycja wszystkich zadaÅ„ projektowych**
   - **Metryki**:
     - 100% zadaÅ„ z faz 1-6 zdekomponowanych
     - KaÅ¼de zadanie ma 3-7 zadaÅ„ atomowych
     - Wszystkie majÄ… metryki i walidacjÄ™
   - **Walidacja**:

     ```bash
     find docs/faza-* -name "*.md" | wc -l
     # Powinno zwrÃ³ciÄ‡ â‰¥40 plikÃ³w
     ```

   - **Sukces**: KaÅ¼de zadanie ma dokument z dekompozycjÄ…
   - **[SzczegÃ³Å‚y â†’](docs/faza-0-dokumentacja/03-dekompozycja-zadan.md)**

4. **[x] Przygotowanie Å›rodowiska developerskiego**
   - **Metryki**:
     - Dev containers dziaÅ‚ajÄ… na Mac OS
     - Remote development przez SSH dziaÅ‚a
     - GPU forwarding skonfigurowany
   - **Walidacja**:

     ```bash
     docker run --rm hello-world
     ssh ubuntu-server "nvidia-smi"
     ```

   - **Sukces**: MoÅ¼na developowaÄ‡ z Mac'a na Ubuntu
   - **[SzczegÃ³Å‚y â†’](docs/faza-0-dokumentacja/04-srodowisko-dev.md)**

5. **[x] Szablon dokumentacji technicznej**
   - **Metryki**:
     - Templates dla: API, Architecture, Runbook
     - Style guide utworzony
     - Automated docs generation dziaÅ‚a
   - **Walidacja**:

     ```bash
     mkdocs build
     vale docs/ # linter dokumentacji
     ```

   - **Sukces**: Dokumentacja generuje siÄ™ automatycznie
   - **[SzczegÃ³Å‚y â†’](docs/faza-0-dokumentacja/05-szablon-dokumentacji.md)**

### Faza 1: Fundament z Observability (2-3 tygodnie) âœ… **COMPLETED**

#### Zadania i Metryki

1. **[x] Konfiguracja Å›rodowiska Docker na serwerze Ubuntu** âœ…
   - **Metryka**: Docker daemon dziaÅ‚a, docker-compose v2.20+
   - **Walidacja**: `docker run hello-world && docker compose version`
   - **Sukces**: Zwraca wersjÄ™ â‰¥ 2.20, hello-world dziaÅ‚a
   - **[SzczegÃ³Å‚y â†’](docs/faza-1-fundament/01-konfiguracja-docker.md)**

2. **[x] Instalacja NVIDIA Container Toolkit** âœ…
   - **Metryka**: GPU dostÄ™pne w kontenerach
   - **Walidacja**: `docker run --rm --gpus all nvidia/cuda:12.0-base nvidia-smi`
   - **Sukces**: Pokazuje GTX 4070 Super, CUDA 12.0+
   - **[SzczegÃ³Å‚y â†’](docs/faza-1-fundament/02-nvidia-toolkit.md)**

3. **[x] Setup repozytorium Git z podstawowÄ… strukturÄ…** âœ…
   - **Metryka**: Struktura katalogÃ³w zgodna z Clean Architecture
   - **Walidacja**: `tree -d -L 3` pokazuje wymaganÄ… strukturÄ™
   - **Sukces**: IstniejÄ…: services/, docs/, tests/, .github/
   - **[SzczegÃ³Å‚y â†’](docs/faza-1-fundament/03-git-repository-setup.md)**

4. **[x] Deploy stack observability: Jaeger, Prometheus, Grafana, Loki** âœ…
   - **Metryki**:
     - Jaeger UI: <http://localhost:16686>
     - Prometheus: <http://localhost:9090>
     - Grafana: <http://localhost:3000>
     - Loki query: `{job="detektor"}`
   - **Walidacja**: `curl -s http://localhost:9090/-/healthy | grep "Prometheus Server is Healthy"`
   - **Sukces**: Wszystkie 4 UI dostÄ™pne, health check OK
   - **[SzczegÃ³Å‚y â†’](docs/faza-1-fundament/04-observability-stack.md)**

5. **[x] Konfiguracja OpenTelemetry SDK** âœ…
   - **Metryka**: Traces widoczne w Jaeger z example service
   - **Walidacja**: Run example service, sprawdÅº trace w Jaeger UI
   - **Sukces**: Trace zawiera: service name, span duration, attributes
   - **[SzczegÃ³Å‚y â†’](docs/faza-1-fundament/05-opentelemetry-config.md)**

6. **[x] Frame tracking design i implementacja** âœ…
   - [x] Domain model dla frame lifecycle
   - [x] Distributed trace propagation
   - [x] Frame metadata storage (TimescaleDB)
   - [x] Dashboard dla frame journey
   - Dokumentacja: [06-frame-tracking-design.md](./docs/faza-1-fundament/06-frame-tracking-design.md)
   - SzczegÃ³Å‚y â†’ [dekompozycja](./docs/faza-1-fundament/06-frame-tracking-design.md#dekompozycja-na-bloki-zadaÅ„)

7. **[x] TDD setup i pierwsze testy** âœ…
   - **Metryka**: Pytest skonfigurowany, coverage >80%
   - **Walidacja**: `pytest --cov=src tests/`
   - **Sukces**: Testy przechodzÄ…, coverage report generowany
   - **[SzczegÃ³Å‚y â†’](docs/faza-1-fundament/07-tdd-setup.md)**

8. **[x] Monitoring dashboard** âœ…
   - **Metryka**: Grafana dashboard z metrykami systemu
   - **Walidacja**: Dashboard pokazuje CPU, RAM, GPU, Docker metrics
   - **Sukces**: Wszystkie panele dziaÅ‚ajÄ…, dane real-time
   - **[SzczegÃ³Å‚y â†’](docs/faza-1-fundament/08-monitoring-dashboard.md)**

9. **[x] CI/CD Pipeline i Registry-based Deployment** âœ… **NOWE**
   - **Metryki**:
     - GitHub Actions buduje wszystkie obrazy automatycznie
     - Obrazy publikowane do ghcr.io/hretheum/detektr/
     - Deployment na Nebula bez budowania na produkcji
   - **Walidacja**:
     ```bash
     # Push triggers build
     git push origin main
     # Verify deployment
     ssh nebula "/opt/detektor/scripts/health-check-all.sh"
     ```
   - **Sukces**: PeÅ‚ny CI/CD flow od commit do deployment
   - **Dokumentacja**:
     - [CI/CD Setup Guide](docs/CI_CD_SETUP.md)
     - [Deployment Script](scripts/deploy-to-nebula.sh)
     - [Example Service](services/example-otel/)

#### Podsumowanie Fazy 1

**Status**: âœ… **COMPLETED** (wszystkie zadania ukoÅ„czone)

**Kluczowe osiÄ…gniÄ™cia**:
- PeÅ‚na infrastruktura observability (Prometheus, Jaeger, Grafana)
- CI/CD pipeline z GitHub Actions i GitHub Container Registry
- Automatyczny deployment na serwer Nebula
- PrzykÅ‚adowy serwis (example-otel) z peÅ‚nym observability
- Secrets management przez SOPS
- Health monitoring wszystkich serwisÃ³w

**Strategia deployment** (obowiÄ…zkowa dla wszystkich kolejnych faz):
1. **Build**: Obrazy budowane TYLKO w GitHub Actions
2. **Registry**: Publikacja do ghcr.io
3. **Deploy**: Pull z registry na Nebula (NIGDY build na produkcji)
4. **Monitor**: Health checks i observability od poczÄ…tku

### Faza 2: Akwizycja i Storage z peÅ‚nym monitoringiem (2-3 tygodnie)

#### Zadania i Metryki

1. **Implementacja RTSP capture service z OpenTelemetry** âœ… **COMPLETED**
   - **Metryki**:
     - FPS capture rate: 10-30 fps
     - Frame loss: <0.1%
     - Latency: <50ms
   - **Walidacja**:

     ```bash
     curl http://localhost:8001/metrics | grep rtsp_frames_captured_total
     # Trace w Jaeger: service="rtsp-capture" operation="capture_frame"
     ```

   - **Sukces**: Stable 10+ FPS, traces pokazujÄ… kaÅ¼dÄ… klatkÄ™
   - **Status produkcyjny**:
     - Service running: http://nebula:8001 âœ…
     - Reolink camera configured âœ…
     - Status: "degraded" (waiting for Redis) âœ…
   - **[SzczegÃ³Å‚y â†’](docs/faza-2-akwizycja/01-rtsp-capture-service.md)**
   - **Completed blocks**:
     - [x] Block 0: Prerequisites (ADR, API spec, tests, environment setup)
     - [x] Block 1: Core implementation
     - [x] Block 2: Integration & monitoring
     - [x] Block 3: Testing & validation
     - [x] Block 4: Deployment on Nebula
     - [x] Block 5: Production readiness

2. **Frame Buffer z Redis/RabbitMQ** âœ… **COMPLETED**
   - **Metryki**:
     - Throughput: 80,239 frames/second (osiÄ…gniÄ™to, target: 1000+)
     - Latency: 0.01ms queue overhead (osiÄ…gniÄ™to, target: <10ms)
     - Reliability: 0% frame loss (osiÄ…gniÄ™to)
   - **Walidacja**:

     ```bash
     curl http://nebula:8002/health  # Health check
     curl http://nebula:8002/metrics | grep frame_buffer  # Prometheus metrics
     # Dead Letter Queue stats, backpressure metrics
     ```
   - **Status produkcyjny**:
     - Service running: http://nebula:8002 âœ…
     - Redis Streams backend with persistence âœ…
     - CI/CD pipeline: frame-buffer-deploy.yml âœ…
   - **[SzczegÃ³Å‚y â†’](docs/faza-2-akwizycja/02-frame-buffer-redis.md)**

3. **Redis/RabbitMQ Configuration** âœ… **COMPLETED**
   - **Metryki**:
     - Disk space: +100GB extended, 22GB cleaned
     - Redis performance: >160k ops/sec, <0.23ms latency
     - Load test: 714 msg/s sustained, 100% success rate
     - Redis memory limit: 4GB configured
     - Monitoring: Telegram alerts active
   - **Walidacja**:
     ```bash
     ssh nebula "df -h /"  # 154GB free
     ssh nebula "docker exec detektor-redis-1 redis-cli INFO memory"
     curl -s http://nebula:9090/metrics | grep redis
     ```
   - **Sukces**: All services in single network, monitoring active
   - **Status produkcyjny**:
     - LVM volumes created: /data/redis (50GB), /data/postgres (100GB), /data/frames (50GB)
     - Docker networks unified (fixed multi-network issue)
     - Telegram alerts deployed (disk >80%, Redis >3.5GB)
     - SOPS encryption configured
     - Grafana dashboard: http://192.168.1.193:3000/d/broker-metrics/message-broker-metrics
   - **[SzczegÃ³Å‚y â†’](docs/faza-2-akwizycja/02-redis-rabbitmq-config.md)**

4. **Setup PostgreSQL/TimescaleDB z monitoringiem**
   - **Metryki**:
     - Connection pool: <80% utilized
     - Query latency p99: <100ms
     - Hypertable compression: >10:1
   - **Walidacja**:

     ```sql
     SELECT * FROM timescaledb_information.hypertables;
     SELECT * FROM pg_stat_activity WHERE state = 'active';
     ```

   - **Sukces**: Hypertable utworzona, continuous aggregates dziaÅ‚ajÄ…
   - **[SzczegÃ³Å‚y â†’](docs/faza-2-akwizycja/03-postgresql-timescale.md)**

5. **Frame tracking z distributed tracing od wejÅ›cia**
   - **Metryka**: KaÅ¼da klatka ma trace_id i span przez caÅ‚y pipeline
   - **Walidacja**:

     ```python
     # Test script sprawdzajÄ…cy frame metadata
     assert frame.trace_id is not None
     assert len(frame.processing_spans) > 0
     ```

   - **Sukces**: 100% klatek ma kompletny trace
   - **[SzczegÃ³Å‚y â†’](docs/faza-2-akwizycja/04-frame-tracking.md)**

6. **Dashboard: Frame Pipeline Overview**
   - **Metryki na dashboardzie**:
     - Frames per second (live)
     - Processing latency histogram
     - Queue depths
     - Error rate
   - **Walidacja**: Import dashboard JSON do Grafana
   - **Sukces**: Wszystkie panele pokazujÄ… dane real-time
   - **[SzczegÃ³Å‚y â†’](docs/faza-2-akwizycja/05-dashboard-frame-pipeline.md)**

7. **Alerty: frame drop, latency, queue size**
   - **Alerty**:
     - Frame drop rate > 1%
     - Processing latency p95 > 200ms
     - Queue size > 5000
   - **Walidacja**: Trigger test conditions, check alert manager
   - **Sukces**: Alerty firing w <1 min od warunku
   - **[SzczegÃ³Å‚y â†’](docs/faza-2-akwizycja/06-alerts-configuration.md)**

### Faza 3: AI Services - Podstawy (3-4 tygodnie)

#### Zadania i Metryki

1. **Face recognition service z metrykami i tracingiem**
   - **Metryki**:
     - Accuracy: >95% na test dataset
     - Inference time: <100ms/frame
     - GPU utilization: 40-80%
   - **Walidacja**:

     ```bash
     pytest tests/test_face_recognition.py --benchmark
     nvidia-smi dmon -s um -i 0 # GPU monitoring
     ```

   - **Sukces**: mAP >0.95, p99 latency <100ms
   - **[SzczegÃ³Å‚y â†’](docs/faza-3-ai-services/01-face-recognition-service.md)**

2. **Object detection z metrykami GPU i tracingiem**
   - **Metryki**:
     - YOLO v8 mAP: >0.85
     - FPS: >10 na 1080p
     - Memory usage: <4GB VRAM
   - **Walidacja**:

     ```python
     # Benchmark script
     results = model.val(data='test_dataset.yaml')
     print(f"mAP: {results.box.map}")
     ```

   - **Sukces**: Detects persons, animals, vehicles reliably
   - **[SzczegÃ³Å‚y â†’](docs/faza-3-ai-services/02-object-detection.md)**

3. **Event bus (Kafka/NATS) z peÅ‚nym monitoringiem**
   - **Metryki**:
     - Message throughput: >1000 msg/s
     - Latency p99: <10ms
     - Partition lag: <100
   - **Walidacja**:

     ```bash
     kafka-run-class kafka.tools.ConsumerOffsetChecker
     nats-top -s localhost:8222
     ```

   - **Sukces**: Zero message loss pod load testem
   - **[SzczegÃ³Å‚y â†’](docs/faza-3-ai-services/03-event-bus-setup.md)**

4. **Dashboard: AI Processing Performance**
   - **Panele**:
     - GPU utilization over time
     - Model inference latency
     - Detection confidence distribution
     - Errors by type
   - **Walidacja**: Grafana dashboard z przykÅ‚adowymi danymi
   - **Sukces**: Real-time GPU metrics, heatmap latency
   - **[SzczegÃ³Å‚y â†’](docs/faza-3-ai-services/04-dashboard-ai-performance.md)**

5. **Trace: peÅ‚ny flow od klatki do wyniku AI**
   - **Metryka**: End-to-end trace pokazuje wszystkie kroki
   - **Walidacja**:

     ```
     Jaeger: frame_capture â†’ queue â†’ ai_inference â†’ result_publish
     Each span has: duration, GPU metrics, result count
     ```

   - **Sukces**: <5% traces z missing spans
   - **[SzczegÃ³Å‚y â†’](docs/faza-3-ai-services/05-end-to-end-tracing.md)**

6. **Testy wydajnoÅ›ciowe z analizÄ… w Grafanie**
   - **Metryki**:
     - Throughput: >10 FPS sustained
     - Resource usage stable over 1h
     - No memory leaks
   - **Walidacja**: Run locust/k6 load test for 1 hour
   - **Sukces**: Performance report w Grafana, no degradation
   - **[SzczegÃ³Å‚y â†’](docs/faza-3-ai-services/06-performance-testing.md)**

### Faza 4: Integracja z Home Assistant (2 tygodnie)

#### Zadania i Metryki

1. **MQTT bridge z metrykami publikacji/subskrypcji**
   - **Metryki**:
     - Message delivery rate: >99.9%
     - Publish latency: <50ms
     - Active subscriptions: correct count
   - **Walidacja**:

     ```bash
     mosquitto_sub -h localhost -t "detektor/#" -v
     curl http://localhost:9090/metrics | grep mqtt_messages_published_total
     ```

   - **Sukces**: Wszystkie eventy docierajÄ… do HA
   - **[SzczegÃ³Å‚y â†’](docs/faza-4-integracja/01-mqtt-bridge.md)**

2. **HA Bridge service z tracingiem akcji**
   - **Metryki**:
     - API call success rate: >99%
     - Action execution time: <500ms
     - Retry rate: <5%
   - **Walidacja**:

     ```python
     # Test HA integration
     response = ha_client.call_service('light.turn_on', entity_id='light.living_room')
     assert response.status == 'success'
     ```

   - **Sukces**: Trace pokazuje: detection â†’ decision â†’ HA call â†’ result
   - **[SzczegÃ³Å‚y â†’](docs/faza-4-integracja/02-ha-bridge-service.md)**

3. **Dashboard: Automation Execution**
   - **Panele**:
     - Automations triggered/hour
     - Success/failure rate
     - Latency distribution
     - Most common triggers
   - **Walidacja**: Test dashboard z symulowanymi automatyzacjami
   - **Sukces**: Live view dziaÅ‚ajÄ…cych automatyzacji
   - **[SzczegÃ³Å‚y â†’](docs/faza-4-integracja/03-dashboard-automation.md)**

4. **Trace: od detekcji do wykonania automatyzacji**
   - **Metryka**: Complete trace z wszystkimi krokami
   - **Walidacja**:

     ```
     Trace path: object_detected â†’ intent_recognized â†’
                 automation_triggered â†’ ha_service_called â†’
                 action_completed
     ```

   - **Sukces**: E2E latency <2s w 95% przypadkÃ³w
   - **[SzczegÃ³Å‚y â†’](docs/faza-4-integracja/04-automation-tracing.md)**

5. **Testowanie scenariuszy z peÅ‚nÄ… widocznoÅ›ciÄ…**
   - **Scenariusze**:
     - Person at door â†’ notification
     - Gesture stop â†’ turn off music
     - Pet in kitchen â†’ alert
   - **Walidacja**: Automated test suite z assertions
   - **Sukces**: 10/10 scenariuszy dziaÅ‚a poprawnie
   - **[SzczegÃ³Å‚y â†’](docs/faza-4-integracja/05-scenario-testing.md)**

### Faza 5: Zaawansowane AI i Voice (3-4 tygodnie)

#### Zadania i Metryki

1. **Gesture detection z metrykami i tracingiem**
   - **Metryki**:
     - Recognition accuracy: >90% (5 basic gestures)
     - Processing latency: <150ms
     - False positive rate: <5%
   - **Walidacja**:

     ```python
     # Test gesture recognition
     gestures = ['stop', 'thumbs_up', 'wave', 'point', 'peace']
     accuracy = test_gesture_model(test_dataset, gestures)
     assert accuracy > 0.9
     ```

   - **Sukces**: MediaPipe tracks 21 hand landmarks reliably
   - **[SzczegÃ³Å‚y â†’](docs/faza-5-advanced-ai/01-gesture-detection.md)**

2. **Voice processing (Whisper) z metrykami STT**
   - **Metryki**:
     - WER (Word Error Rate): <10% for Polish
     - Processing time: <2s for 10s audio
     - Memory usage: <2GB
   - **Walidacja**:

     ```bash
     # Benchmark Whisper
     python benchmark_whisper.py --language pl --model medium
     ```

   - **Sukces**: Real-time factor <0.2 (5x faster than real-time)
   - **[SzczegÃ³Å‚y â†’](docs/faza-5-advanced-ai/02-voice-processing.md)**

3. **LLM integration z metrykami API calls i kosztÃ³w**
   - **Metryki**:
     - Intent recognition accuracy: >95%
     - API latency p99: <3s
     - Cost per request: <$0.02
   - **Walidacja**:

     ```python
     # Track API usage
     metrics = llm_client.get_usage_stats()
     assert metrics['cost_today'] < daily_budget
     assert metrics['success_rate'] > 0.95
     ```

   - **Sukces**: Circuit breaker dziaÅ‚a, costs tracked in Grafana
   - **[SzczegÃ³Å‚y â†’](docs/faza-5-advanced-ai/03-llm-integration.md)**

4. **Dashboard: Voice & Intent Processing**
   - **Panele**:
     - Voice commands/hour
     - Intent recognition success rate
     - Language distribution
     - API costs over time
   - **Walidacja**: Live data z voice commands
   - **Sukces**: Cost alerts, WER tracking, latency heatmap
   - **[SzczegÃ³Å‚y â†’](docs/faza-5-advanced-ai/04-dashboard-voice-intent.md)**

5. **End-to-end trace: gÅ‚os â†’ intent â†’ akcja**
   - **Metryka**: Complete voice command execution trace
   - **Walidacja**:

     ```
     Trace: audio_capture â†’ whisper_stt â†’ text_normalization â†’
            llm_intent â†’ action_mapping â†’ ha_execution
     ```

   - **Sukces**: Voice to action <5s w 90% przypadkÃ³w
   - **[SzczegÃ³Å‚y â†’](docs/faza-5-advanced-ai/05-voice-to-action-trace.md)**

### Faza 6: Optymalizacja i Refinement (2-3 tygodnie)

#### Zadania i Metryki

1. **Analiza bottleneckÃ³w na podstawie metryk**
   - **Metryki**:
     - Zidentyfikowane top 3 bottlenecks
     - Baseline performance metrics
     - Resource utilization patterns
   - **Walidacja**:

     ```sql
     -- Jaeger slow queries
     SELECT operation_name, percentile_cont(0.95)
     WITHIN GROUP (ORDER BY duration) as p95_latency
     FROM spans GROUP BY operation_name
     ORDER BY p95_latency DESC LIMIT 10;
     ```

   - **Sukces**: Bottleneck analysis report z rekomendacjami
   - **[SzczegÃ³Å‚y â†’](docs/faza-6-optymalizacja/01-bottleneck-analysis.md)**

2. **Optymalizacja pipeline'u uÅ¼ywajÄ…c danych z Jaeger**
   - **Metryki**:
     - E2E latency reduction: >30%
     - Throughput increase: >50%
     - Resource usage: -20%
   - **Walidacja**: Before/after performance tests
   - **Sukces**: p95 latency <1.5s (from 2s+)
   - **[SzczegÃ³Å‚y â†’](docs/faza-6-optymalizacja/02-pipeline-optimization.md)**

3. **Rozbudowa automatyzacji z monitoringiem**
   - **Metryki**:
     - 20+ automation rules
     - <1% false positive rate
     - Automation coverage: 90%
   - **Walidacja**: Test kaÅ¼dej automatyzacji z metrykami
   - **Sukces**: Wszystkie automatyzacje majÄ… traces i alerts
   - **[SzczegÃ³Å‚y â†’](docs/faza-6-optymalizacja/03-automation-expansion.md)**

4. **UI/Dashboard do zarzÄ…dzania systemem**
   - **Features**:
     - Live camera view z bounding boxes
     - System health overview
     - Automation rule editor
     - Alert configuration
   - **Walidacja**: UI responsive <200ms
   - **Sukces**: Web UI dziaÅ‚a na mobile i desktop
   - **[SzczegÃ³Å‚y â†’](docs/faza-6-optymalizacja/04-management-ui.md)**

5. **Consolidated monitoring dashboard**
   - **Metryki na jednym dashboardzie**:
     - System health score (0-100)
     - All service statuses
     - Resource usage trends
     - Cost tracking
   - **Walidacja**: Single pane of glass dla caÅ‚ego systemu
   - **Sukces**: 1-click drill-down do problemÃ³w
   - **[SzczegÃ³Å‚y â†’](docs/faza-6-optymalizacja/05-consolidated-dashboard.md)**

6. **Dokumentacja z przykÅ‚adami trace'Ã³w**
   - **Dokumenty**:
     - Troubleshooting guide z traces
     - Performance tuning guide
     - Automation cookbook
     - API reference
   - **Walidacja**: Peer review dokumentacji
   - **Sukces**: New developer onboarding <1 day
   - **[SzczegÃ³Å‚y â†’](docs/faza-6-optymalizacja/06-documentation-traces.md)**

## 3. Struktura Dokumentacji

### 3.1 Dokumentacja Techniczna

```
docs/
â”œâ”€â”€ requirements/
â”‚   â”œâ”€â”€ functional-requirements.md
â”‚   â”œâ”€â”€ non-functional-requirements.md
â”‚   â”œâ”€â”€ hardware-requirements.md
â”‚   â””â”€â”€ use-cases.md
â”œâ”€â”€ architecture/
â”‚   â”œâ”€â”€ system-overview.md
â”‚   â”œâ”€â”€ component-design.md
â”‚   â”œâ”€â”€ data-flow.md
â”‚   â””â”€â”€ security-considerations.md
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ rest-api.md
â”‚   â”œâ”€â”€ mqtt-topics.md
â”‚   â””â”€â”€ event-schemas.md
â”œâ”€â”€ deployment/
â”‚   â”œâ”€â”€ installation-guide.md
â”‚   â”œâ”€â”€ configuration.md
â”‚   â””â”€â”€ troubleshooting.md
â””â”€â”€ development/
    â”œâ”€â”€ setup-dev-environment.md
    â”œâ”€â”€ coding-standards.md
    â””â”€â”€ testing-strategy.md
```

### 3.2 Wymagania - Szablon

#### Wymagania Funkcjonalne

- **RF001**: System musi przechwytywaÄ‡ obraz z kamery IP w rozdzielczoÅ›ci min. 1080p
- **RF002**: System musi wykrywaÄ‡ twarze z dokÅ‚adnoÅ›ciÄ… >95%
- **RF003**: System musi rozpoznawaÄ‡ podstawowe gesty (min. 5 typÃ³w)
- **RF004**: System musi integrowaÄ‡ siÄ™ z Home Assistant przez MQTT
- **RF005**: System musi umoÅ¼liwiaÄ‡ sterowanie gÅ‚osowe w jÄ™zyku polskim

#### Wymagania Niefunkcjonalne

- **RNF001**: Latencja end-to-end < 2 sekundy
- **RNF002**: System musi przetwarzaÄ‡ min. 10 FPS
- **RNF003**: DostÄ™pnoÅ›Ä‡ systemu > 99%
- **RNF004**: Wszystkie dane muszÄ… byÄ‡ szyfrowane w tranzycie
- **RNF005**: System musi dziaÅ‚aÄ‡ na podanej konfiguracji sprzÄ™towej

#### Przypadki UÅ¼ycia

- **UC001**: Wykrycie osoby przy drzwiach â†’ powiadomienie + zapis
- **UC002**: Gest "stop" â†’ wyÅ‚Ä…czenie muzyki
- **UC003**: Komenda gÅ‚osowa â†’ wykonanie automatyzacji
- **UC004**: Wykrycie zwierzÄ™cia â†’ alert jeÅ›li w zakazanej strefie

## 4. Praktyki Development i Architektura

<!--
LLM DEVELOPMENT PROMPT:
Ta sekcja definiuje HOW we write code w projekcie.
Kluczowe zasady:
1. TDD ZAWSZE - test first, implementation second
2. Clean Architecture - separacja warstw (domain, infra, app)
3. SOLID principles w kaÅ¼dym komponencie
4. Event Sourcing dla frame tracking
5. Observability wbudowana od poczÄ…tku (nie jako afterthought)

Przy implementacji nowego serwisu:
- UÅ¼yj BaseService template (sekcja 1.4)
- Struktura katalogÃ³w jak w sekcji 4.2
- Testy na 3 poziomach (unit, integration, e2e)
-->

### 4.1 Test-Driven Development (TDD)

#### Cykl TDD

1. **RED**: Napisz test ktÃ³ry nie przechodzi
2. **GREEN**: Napisz minimalny kod aby test przeszedÅ‚
3. **REFACTOR**: Popraw kod zachowujÄ…c zielone testy

#### Struktura TestÃ³w

```python
# tests/unit/test_frame_processor.py
import pytest
from unittest.mock import Mock, patch

class TestFrameProcessor:
    def test_should_assign_unique_id_to_frame(self):
        # Given
        processor = FrameProcessor()
        frame_data = Mock()

        # When
        result = processor.process(frame_data)

        # Then
        assert result.frame_id is not None
        assert isinstance(result.frame_id, str)

    def test_should_emit_telemetry_on_processing(self):
        # Given
        processor = FrameProcessor()
        with patch('opentelemetry.trace.get_tracer') as mock_tracer:
            # When
            processor.process(Mock())

            # Then
            mock_tracer.return_value.start_span.assert_called_once()
```

#### Poziomy TestÃ³w

- **Unit Tests**: 80% pokrycia, <100ms na test
- **Integration Tests**: Testowanie granic serwisÃ³w
- **E2E Tests**: Kluczowe scenariusze biznesowe
- **Performance Tests**: Baseline dla kaÅ¼dego serwisu

### 4.2 Wzorce Architektoniczne

#### Clean Architecture / Hexagonal Architecture

```
services/
â”œâ”€â”€ face-recognition/
â”‚   â”œâ”€â”€ domain/           # Logika biznesowa (bez zaleÅ¼noÅ›ci)
â”‚   â”‚   â”œâ”€â”€ entities/
â”‚   â”‚   â”œâ”€â”€ use_cases/
â”‚   â”‚   â””â”€â”€ interfaces/
â”‚   â”œâ”€â”€ infrastructure/   # Adaptery (DB, API, Queue)
â”‚   â”‚   â”œâ”€â”€ repositories/
â”‚   â”‚   â”œâ”€â”€ messaging/
â”‚   â”‚   â””â”€â”€ api/
â”‚   â”œâ”€â”€ application/      # Orchestracja
â”‚   â”‚   â””â”€â”€ services/
â”‚   â””â”€â”€ tests/
â”‚       â”œâ”€â”€ unit/
â”‚       â”œâ”€â”€ integration/
â”‚       â””â”€â”€ e2e/
```

#### Domain-Driven Design (DDD)

- **Bounded Contexts**: Frame Processing, AI Detection, Home Automation
- **Aggregates**: Frame, DetectionResult, AutomationAction
- **Domain Events**: FrameCaptured, ObjectDetected, ActionTriggered

#### SOLID Principles

```python
# Single Responsibility
class FrameCapture:
    def capture_frame(self) -> Frame:
        pass

# Open/Closed + Dependency Inversion
class DetectionService(ABC):
    @abstractmethod
    def detect(self, frame: Frame) -> DetectionResult:
        pass

class FaceDetectionService(DetectionService):
    def detect(self, frame: Frame) -> DetectionResult:
        # Implementacja
        pass

# Interface Segregation
class Readable(Protocol):
    def read(self) -> bytes:
        pass

class Writable(Protocol):
    def write(self, data: bytes) -> None:
        pass
```

### 4.3 Wzorce Projektowe

#### Repository Pattern

```python
class FrameRepository(ABC):
    @abstractmethod
    async def save(self, frame: Frame) -> None:
        pass

    @abstractmethod
    async def get_by_id(self, frame_id: str) -> Optional[Frame]:
        pass

class PostgresFrameRepository(FrameRepository):
    def __init__(self, connection_pool):
        self._pool = connection_pool

    async def save(self, frame: Frame) -> None:
        # Implementacja z tracingiem
        with self.tracer.start_as_current_span("save_frame"):
            # ...
```

#### Event Sourcing dla Frame Tracking

```python
@dataclass
class FrameEvent:
    frame_id: str
    event_type: str
    timestamp: datetime
    data: Dict[str, Any]

class FrameEventStore:
    async def append(self, event: FrameEvent) -> None:
        # Zapisz event z metrykami
        pass

    async def get_frame_history(self, frame_id: str) -> List[FrameEvent]:
        # OdtwÃ³rz historiÄ™ klatki
        pass
```

#### Circuit Breaker dla External Services

```python
class LLMServiceCircuitBreaker:
    def __init__(self, failure_threshold: int = 5):
        self._failure_count = 0
        self._threshold = failure_threshold
        self._is_open = False

    async def call_llm(self, prompt: str) -> str:
        if self._is_open:
            raise CircuitOpenError()

        try:
            result = await self._llm_client.complete(prompt)
            self._failure_count = 0
            return result
        except Exception as e:
            self._failure_count += 1
            if self._failure_count >= self._threshold:
                self._is_open = True
            raise
```

### 4.4 Praktyki CI/CD

#### Pre-commit Hooks

```yaml
# .pre-commit-config.yaml
repos:
  - repo: https://github.com/psf/black
    hooks:
      - id: black
  - repo: https://github.com/PyCQA/flake8
    hooks:
      - id: flake8
  - repo: https://github.com/pre-commit/mirrors-mypy
    hooks:
      - id: mypy
```

#### GitHub Actions Pipeline

```yaml
# .github/workflows/ci.yml
name: CI
on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Run Tests
        run: |
          docker-compose -f docker-compose.test.yml up --abort-on-container-exit
      - name: Upload Coverage
        uses: codecov/codecov-action@v3
```

### 4.5 Code Quality Standards

#### Type Hints i Static Analysis

```python
from typing import Protocol, TypeVar, Generic

T = TypeVar('T')

class Processor(Protocol[T]):
    def process(self, item: T) -> T:
        ...

def create_pipeline(processors: list[Processor[Frame]]) -> Pipeline[Frame]:
    return Pipeline(processors)
```

#### Documentation Standards

```python
def detect_objects(frame: Frame, confidence: float = 0.8) -> list[Detection]:
    """
    Detect objects in a given frame.

    Args:
        frame: Input frame to process
        confidence: Minimum confidence threshold (0.0-1.0)

    Returns:
        List of detected objects with bounding boxes

    Raises:
        InvalidFrameError: If frame is corrupted
        ModelNotLoadedError: If detection model not initialized

    Example:
        >>> frame = capture_frame()
        >>> detections = detect_objects(frame, confidence=0.9)
        >>> print(f"Found {len(detections)} objects")
    """
```

## 5. Technologie i NarzÄ™dzia

### Backend

- **Python 3.11+**: GÅ‚Ã³wny jÄ™zyk implementacji
- **FastAPI**: REST API
- **OpenCV**: Przetwarzanie obrazu
- **PyTorch/TensorFlow**: Modele AI
- **Celery**: Kolejkowanie zadaÅ„

### AI/ML

- **YOLO v8**: Detekcja obiektÃ³w
- **FaceNet/InsightFace**: Rozpoznawanie twarzy
- **MediaPipe**: Detekcja gestÃ³w
- **Whisper**: Speech-to-text
- **OpenAI/Anthropic API**: LLM dla intent recognition

### Infrastructure

- **Docker + Docker Compose**: Konteneryzacja
- **NVIDIA Container Toolkit**: GPU w kontenerach
- **Traefik**: Reverse proxy
- **MinIO**: Object storage dla klatek

### Observability

- **OpenTelemetry**: Standard dla telemetrii
- **Jaeger**: Distributed tracing
- **Prometheus**: Metryki
- **Grafana**: Wizualizacja
- **Loki**: Agregacja logÃ³w

## 5. BezpieczeÅ„stwo

- **SieÄ‡ izolowana**: VLAN dla urzÄ…dzeÅ„ IoT
- **TLS everywhere**: Szyfrowanie komunikacji
- **API Keys**: Dla dostÄ™pu do usÅ‚ug chmurowych
- **RBAC**: Role-based access control
- **Secrets management**: Docker secrets/Vault

## 6. Estymacja KosztÃ³w

### Koszty jednorazowe

- Kamera IP PoE: 300-500 PLN
- Switch PoE: 200-300 PLN
- Kable, akcesoria: 100 PLN

### Koszty miesiÄ™czne

- LLM API (OpenAI/Anthropic): ~$20-50/miesiÄ…c
- Backup storage (opcjonalnie): ~$5/miesiÄ…c
- Domena + SSL (opcjonalnie): ~$10/rok

### Infrastruktura

- Serwer Ubuntu: juÅ¼ posiadany
- Home Assistant: juÅ¼ posiadany
- Wszystkie usÅ‚ugi self-hosted: $0

## 7. NastÄ™pne Kroki

1. **Walidacja wymagaÅ„**: PrzeglÄ…d i doprecyzowanie wymagaÅ„
2. **Proof of Concept**: Prosty pipeline kamera â†’ detekcja â†’ akcja
3. **WybÃ³r technologii**: Finalna decyzja o stacku technologicznym
4. **Setup Å›rodowiska**: Przygotowanie dev environment na Mac OS
5. **RozpoczÄ™cie Fazy 1**: Implementacja fundamentÃ³w systemu
